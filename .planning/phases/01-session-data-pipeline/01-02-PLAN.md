---
phase: 01-session-data-pipeline
plan: 02
type: execute
wave: 2
depends_on:
  - 01-01
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "Running `gsd-tools.js extract-messages <project>` extracts only genuine user messages (type=user, userType=external, not meta, not sidechain, string content, no system prefixes)"
    - "Extraction on a 20MB session file completes without exceeding 512MB process memory"
    - "Extracted messages are truncated to 2000 chars each and limited to 300 messages per batch"
    - "Output is written to a temp file in JSONL format, with the path returned in JSON output"
    - "Each extracted message includes sessionId, projectPath, timestamp, and content fields"
    - "Corrupted or unreadable session files are skipped with a warning, not a crash"
    - "Progress indicator shows on stderr during processing"
    - "Tests pass for scan-sessions, extract-messages, and loadConfig extension"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "extract-messages command, message filtering, streaming extraction"
      contains: "cmdExtractMessages"
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Tests for scan-sessions and extract-messages commands"
      contains: "scan-sessions"
  key_links:
    - from: "main() switch"
      to: "cmdExtractMessages()"
      via: "case 'extract-messages' dispatch"
      pattern: "case 'extract-messages'"
    - from: "cmdExtractMessages()"
      to: "streamExtractMessages()"
      via: "function call for JSONL streaming"
      pattern: "streamExtractMessages"
    - from: "streamExtractMessages()"
      to: "isGenuineUserMessage()"
      via: "filter function applied to each parsed JSONL line"
      pattern: "isGenuineUserMessage"
    - from: "cmdExtractMessages()"
      to: "temp file output"
      via: "fs.appendFileSync to temp JSONL file"
      pattern: "appendFileSync.*outputPath"
---

<objective>
Build the `extract-messages` command and comprehensive tests for the entire session data pipeline.

Purpose: The extraction command is the core data pipeline -- it reads JSONL session files, filters for genuine user messages using a multi-step filter chain, truncates them for safety, and writes the result to a temp file for downstream profiling (Phase 2). Tests validate all Phase 1 functionality end-to-end, ensuring helpers, scan-sessions, extract-messages, and config extension all work correctly.

Output: `gsd-tools.js` extended with `extract-messages` command. `gsd-tools.test.js` extended with tests covering both new commands.
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-session-data-pipeline/01-RESEARCH.md
@.planning/phases/01-session-data-pipeline/01-CONTEXT.md
@.planning/phases/01-session-data-pipeline/01-01-SUMMARY.md
@.planning/codebase/CONVENTIONS.md
@.planning/codebase/TESTING.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/bin/gsd-tools.test.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement extract-messages command with streaming extraction</name>
  <files>get-shit-done/bin/gsd-tools.js</files>
  <action>
Add the `readline` import at the top of the file if not already present: `const readline = require('readline');`

Implement the following functions:

1. **`isGenuineUserMessage(record)`** - Multi-step filter for genuine user messages.
   - Return false if `record.type !== 'user'`
   - Return false if `record.userType !== 'external'`
   - Return false if `record.isMeta === true`
   - Return false if `record.isSidechain === true`
   - Get content: `record.message?.content`
   - Return false if `typeof content !== 'string'` (skip array content -- tool results)
   - Return false if `content.length === 0`
   - Return false if content starts with `<local-command`
   - Return false if content starts with `<command-`
   - Return false if content starts with `<task-notification`
   - Return false if content starts with `<local-command-stdout`
   - Return true
   - Per research: this filter chain is verified against actual JSONL data across 5 projects

2. **`truncateContent(content, maxLen = 2000)`** - Truncate message content per PIPE-05.
   - If `content.length <= maxLen`: return content
   - Else: return `content.substring(0, maxLen) + '... [truncated]'`

3. **`async streamExtractMessages(filePath, filterFn, maxMessages = 300)`** - Stream JSONL file, apply filter, collect messages.
   - Create `readline.createInterface({ input: fs.createReadStream(filePath), crlfDelay: Infinity, terminal: false })`
   - Iterate with `for await (const line of rl)`
   - For each line: try `JSON.parse(line)`, catch and skip malformed lines
   - Apply `filterFn(record)` -- if passes, extract:
     ```
     {
       sessionId: (derive from filename or record),
       projectPath: record.cwd || null,
       timestamp: record.timestamp || null,
       content: truncateContent(record.message.content)
     }
     ```
   - Stop collecting after `maxMessages` (per PIPE-05: 300 limit)
   - Return array of extracted messages

4. **`async cmdExtractMessages(projectArg, options, raw)`** - Main extract command.
   Parameters:
   - `projectArg`: project identifier (fuzzy matched against directory names)
   - `options`: `{ sessionId: string|null, limit: number|null }`
   - `raw`: boolean

   Logic:
   a. Call `getSessionsDir()`. If null: error message (same as scan-sessions)
   b. Read sessions directory, get list of project directories
   c. **Fuzzy match** `projectArg` against directory names:
      - Try exact match first
      - Then case-insensitive substring match
      - If multiple matches: list them and ask user to be more specific
      - If no matches: show error with available projects
      - Per research open question: fuzzy match for beginner-friendliness
   d. Print transparency note to stderr: `"Reading your session history (read-only, nothing is modified or sent anywhere)..."`
   e. Get session files from matched project via `scanProjectDir()`
   f. If `options.sessionId`: filter to just that session file
   g. If `options.limit`: cap the number of sessions processed
   h. Create temp directory: `fs.mkdtempSync(path.join(os.tmpdir(), 'gsd-pipeline-'))`
   i. Create output path: `path.join(tmpDir, 'extracted-messages.jsonl')`
   j. Track stats: `sessionsProcessed`, `sessionsSkipped`, `messagesExtracted`, `messagesTruncated`
   k. For each session file:
      - Show progress on stderr: `"Processing session ${i+1}/${total}..."` (per locked decision)
      - Try `streamExtractMessages(filePath, isGenuineUserMessage)`:
        - On success: append each message as JSONL line to output file via `fs.appendFileSync(outputPath, JSON.stringify(msg) + '\n')`
        - Count truncated messages (where content ends with `... [truncated]`)
        - On error: increment `sessionsSkipped`, write warning to stderr, continue
      - Check total messages extracted. If >= 300 across all sessions: stop (per PIPE-05 batch limit)
   l. Clear progress line on stderr
   m. Build result object:
      ```
      {
        output_file: outputPath,
        project: projectName,
        sessions_processed: N,
        sessions_skipped: N,
        messages_extracted: N,
        messages_truncated: N
      }
      ```
   n. **Exit codes per locked decision:**
      - 0 if no sessions skipped
      - 2 if some sessions skipped (partial success) -- implement via `process.stdout.write(JSON.stringify(result, null, 2)); process.exit(2);`
      - 1 for total failure
   o. Output result via `output(result, raw)` for exit code 0, or custom exit for code 2

**Main dispatch (add to switch-case in `main()`):**
```javascript
case 'extract-messages': {
  const sessionIdx = args.indexOf('--session');
  const sessionId = sessionIdx !== -1 ? args[sessionIdx + 1] : null;
  const limitIdx = args.indexOf('--limit');
  const limit = limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : null;
  const projectArg = args[1];
  if (!projectArg) {
    error('Usage: gsd-tools extract-messages <project> [--session <id>] [--limit N]\nRun scan-sessions first to see available projects.');
  }
  await cmdExtractMessages(projectArg, { sessionId, limit }, raw);
  break;
}
```

Place the case before the `default:` case in the main switch, after `scan-sessions`.
  </action>
  <verify>
Test against actual session data:
1. `node get-shit-done/bin/gsd-tools.js extract-messages get-shit-done` -- should extract user messages and return JSON with output_file path
2. Verify the output file exists and contains JSONL: `head -5 <output_file_path>`
3. Verify messages are genuine user content (no XML-prefixed system messages, no array content)
4. `node get-shit-done/bin/gsd-tools.js extract-messages nonexistent-project` -- should show error with available projects
5. `node get-shit-done/bin/gsd-tools.js extract-messages get-shit-done --limit 2` -- should process only 2 sessions
6. Verify process memory stays reasonable: `node --max-old-space-size=512 get-shit-done/bin/gsd-tools.js extract-messages <largest-project>` completes without OOM
  </verify>
  <done>
`extract-messages` command extracts only genuine user messages, writes JSONL to temp file, returns path in JSON output. Messages truncated at 2000 chars, batch limited to 300 messages. Corrupted files skipped with warning. Progress indicator shown. Exit code 2 for partial success. Memory stays under 512MB for large files.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for scan-sessions, extract-messages, and loadConfig extension</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
Add test suites to the existing test file, following the established patterns (describe blocks, beforeEach/afterEach with temp dirs, runGsdTools helper).

**Test Suite 1: `describe('scan-sessions command', ...)`**

Setup: Create a mock sessions directory structure in temp dir. Create helper that sets up fake Claude sessions data.

Tests:
1. **`test('returns project list with metadata')`**
   - Create a mock project dir with 2 fake JSONL files (minimal valid content)
   - Run `scan-sessions --json --path <tmpDir>`
   - Assert: JSON output is valid, contains project with correct session count

2. **`test('handles missing sessions directory gracefully')`**
   - Run `scan-sessions --path /tmp/nonexistent-gsd-test`
   - Assert: command fails with friendly error message containing "No Claude Code sessions found"

3. **`test('discovers sessions without sessions-index.json')`**
   - Create project dir with JSONL files but no sessions-index.json
   - Run `scan-sessions --json --path <tmpDir>`
   - Assert: sessions discovered from filesystem, correct count returned

4. **`test('enriches metadata from sessions-index.json when present')`**
   - Create project dir with JSONL files AND sessions-index.json with matching entries
   - Run `scan-sessions --json --path <tmpDir>`
   - Assert: result includes enriched data from index (originalPath used for project name)

5. **`test('verbose mode lists individual sessions')`**
   - Create project dir with multiple JSONL files
   - Run `scan-sessions --verbose --json --path <tmpDir>`
   - Assert: output includes sessions array per project

**Test Suite 2: `describe('extract-messages command', ...)`**

Setup: Create mock sessions directory with fake JSONL content containing various message types.

Helper function to create test JSONL content:
```javascript
function createTestSession(messages) {
  return messages.map(m => JSON.stringify(m)).join('\n') + '\n';
}
```

Tests:
1. **`test('extracts only genuine user messages')`**
   - Create JSONL with mix: user/external message, assistant message, user/meta message, user with array content, user with `<local-command` prefix
   - Run `extract-messages <project> --path <tmpDir>`
   - Assert: output_file contains only the genuine user message, not the others

2. **`test('truncates messages over 2000 chars')`**
   - Create JSONL with one user message that is 3000 chars long
   - Run `extract-messages <project> --path <tmpDir>`
   - Read output file, verify message content ends with `... [truncated]` and is <= 2015 chars

3. **`test('limits batch to 300 messages')`**
   - Create JSONL with 350 genuine user messages
   - Run `extract-messages <project> --path <tmpDir>`
   - Assert: messages_extracted <= 300

4. **`test('skips corrupted files and continues')`**
   - Create project with one valid JSONL and one file with invalid JSON on every line
   - Run `extract-messages <project> --path <tmpDir>`
   - Assert: command succeeds (or partial success), messages from valid file are extracted

5. **`test('returns error for unknown project')`**
   - Run `extract-messages nonexistent --path <tmpDir>`
   - Assert: command fails with error listing available projects

6. **`test('--session flag targets single session')`**
   - Create project with multiple JSONL files
   - Run `extract-messages <project> --session <specific-id> --path <tmpDir>`
   - Assert: only messages from that session in output

7. **`test('--limit flag caps sessions processed')`**
   - Create project with 5 JSONL files
   - Run `extract-messages <project> --limit 2 --path <tmpDir>`
   - Assert: sessions_processed <= 2

**Test Suite 3: `describe('loadConfig extension', ...)`**

1. **`test('returns preferences and profile with defaults when missing from config')`**
   - Create config.json without preferences/profile keys
   - Run a command that uses loadConfig (like `state load`) or directly test via `config-ensure-section`
   - Assert: config loads without error

2. **`test('returns preferences and profile from config when present')`**
   - Create config.json with `preferences: { key: "value" }` and `profile: { path: "/test" }`
   - Assert: values loaded correctly

Note: For extract-messages tests, the `--path` flag needs to be supported on extract-messages the same way it is on scan-sessions. If not already added, ensure the extract-messages command also accepts `--path` for testability. Alternatively, create the test sessions directory structure such that the command can find it.

After writing tests, clean up any created temp files in afterEach blocks.
  </action>
  <verify>
Run the full test suite: `npm test` from the project root (or `node --test get-shit-done/bin/gsd-tools.test.js`). All new tests should pass. All existing tests should still pass.
  </verify>
  <done>
All new test suites pass: scan-sessions (5 tests), extract-messages (7 tests), loadConfig extension (2 tests). All existing tests still pass. Total test count increased by ~14 tests.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 01-02 deliverables:

1. **Syntax check:** `node -c get-shit-done/bin/gsd-tools.js` passes
2. **extract-messages basic:** `node get-shit-done/bin/gsd-tools.js extract-messages <project>` produces JSON with output_file path
3. **Output file validation:** temp file exists and contains valid JSONL (one JSON object per line)
4. **Message filtering:** extracted messages contain only genuine user content (no system prefixes, no meta, no sidechain)
5. **Truncation:** no message content exceeds 2015 characters (2000 + `... [truncated]` suffix)
6. **Batch limit:** messages_extracted <= 300
7. **Memory safety:** extraction completes on largest project without OOM under `--max-old-space-size=512`
8. **All tests pass:** `npm test` exits 0
9. **Existing commands:** `node get-shit-done/bin/gsd-tools.js current-timestamp` still works
</verification>

<success_criteria>
- `extract-messages` command extracts only genuine user messages from JSONL session files
- Messages are truncated to 2000 chars, batch limited to 300
- Output written to temp file in JSONL format
- Corrupted files skipped with warning, not crash
- Progress indicator shown during processing
- Exit code 2 for partial success (some files skipped)
- Fuzzy project matching works for beginner-friendliness
- All 14+ new tests pass
- All existing tests still pass
- Memory usage under 512MB for 20MB+ session files
</success_criteria>

<output>
After completion, create `.planning/phases/01-session-data-pipeline/01-02-SUMMARY.md`
</output>
