---
phase: 03-profile-activation
plan: 03
type: execute
wave: 2
depends_on: ["03-02"]
files_modified:
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "generate-dev-preferences produces correct output for session-based analysis JSON"
    - "generate-dev-preferences produces correct output for questionnaire-based analysis JSON"
    - "generate-claude-profile creates new CLAUDE.md when none exists"
    - "generate-claude-profile updates existing CLAUDE.md between markers without disturbing other content"
    - "generate-claude-profile appends section when existing CLAUDE.md has no markers"
    - "All new tests pass alongside existing Phase 1 and Phase 2 tests"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Test suites for generate-dev-preferences and generate-claude-profile subcommands"
      contains: "generate-dev-preferences"
  key_links:
    - from: "get-shit-done/bin/gsd-tools.test.js"
      to: "get-shit-done/bin/gsd-tools.js"
      via: "runGsdTools() test helper calling subcommands"
      pattern: "runGsdTools.*generate-(dev-preferences|claude-profile)"
---

<objective>
Add comprehensive test suites for the two new gsd-tools.js subcommands: `generate-dev-preferences` and `generate-claude-profile`. Tests verify correct template rendering, file creation, marker-based updates, error handling, and JSON output.

Purpose: Ensure artifact generation is reliable and regression-safe. These subcommands are called by the profile-user workflow and must produce correct output deterministically.
Output: New test suites appended to `get-shit-done/bin/gsd-tools.test.js`
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-profile-activation/03-CONTEXT.md

# Implementation reference (from Plan 03-02)
@.planning/phases/03-profile-activation/03-02-SUMMARY.md

# Test pattern reference
@get-shit-done/bin/gsd-tools.test.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Tests for generate-dev-preferences subcommand</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
Add a new `describe('generate-dev-preferences', ...)` test suite to gsd-tools.test.js, following the established test patterns from Phase 2 tests (profile-sample, write-profile, profile-questionnaire suites).

**Test helper setup:** Use the existing `runGsdTools()` helper and temp directory pattern. Create a mock analysis JSON fixture that matches the profiler agent output schema:

```javascript
const MOCK_ANALYSIS = {
  profile_version: '1.0',
  data_source: 'session_analysis',
  projects_analyzed: ['project-a', 'project-b'],
  dimensions: {
    communication_style: {
      rating: 'detailed-structured',
      confidence: 'HIGH',
      claude_instruction: 'Use headers, numbered lists, acknowledge context before responding.',
      summary: 'Consistently provides structured context.',
      cross_project_consistent: true,
      evidence: [{ signal: 'Structured headers in requests', project: 'project-a' }]
    },
    decision_speed: {
      rating: 'deliberate-informed',
      confidence: 'MEDIUM',
      claude_instruction: 'Present comparison tables with trade-offs.',
      summary: 'Prefers to evaluate options before committing.',
      cross_project_consistent: true,
      evidence: []
    },
    // ... remaining 6 dimensions with minimal data
  }
};
```

Fill all 8 dimensions in the fixture (at minimum: rating, confidence, claude_instruction).

**Test cases:**

1. **produces valid dev-preferences file from session analysis JSON**
   - Write mock analysis JSON to temp dir
   - Run `generate-dev-preferences --analysis <path> --output <temp-output-path>`
   - Assert output file exists
   - Assert file contains YAML frontmatter with `description:`
   - Assert file contains "Behavioral Directives" section
   - Assert file contains directive text from mock analysis (e.g., "Use headers, numbered lists")
   - Assert file contains confidence annotations (e.g., "HIGH confidence")
   - Assert JSON output has `command_name: '/gsd:dev-preferences'`
   - Assert JSON output has `dimensions_included >= 2`

2. **renders all 8 dimension sections when all present**
   - Use full mock analysis with all 8 dimensions populated
   - Assert output contains all 8 dimension label headers (Communication, Decision Support, Explanations, Debugging, UX Approach, Library & Tool Choices, Boundaries, Learning Support)

3. **handles questionnaire-only data source correctly**
   - Set `MOCK_ANALYSIS.data_source = 'questionnaire'` in a modified fixture
   - Assert output contains "questionnaire-only profile" in stack preferences section
   - Assert data_source placeholder rendered as "questionnaire"

4. **uses CLAUDE_INSTRUCTIONS fallback when claude_instruction missing**
   - Create analysis JSON where one dimension has no `claude_instruction` field but has a valid `rating`
   - Assert the output still contains a directive for that dimension (pulled from CLAUDE_INSTRUCTIONS lookup)

5. **creates parent directories when output path does not exist**
   - Use `--output` pointing to a nested temp dir that doesn't exist yet
   - Assert the file is created successfully (mkdirSync recursive worked)

6. **errors when analysis file not found**
   - Run with `--analysis /nonexistent/path.json`
   - Assert process exits with non-zero code
   - Assert error message contains "not found"

7. **errors when analysis JSON is malformed**
   - Write invalid JSON to temp file
   - Run with that path
   - Assert error about JSON parsing

8. **accepts --stack option for custom stack preferences**
   - Run with `--stack "TypeScript, React, Node.js"`
   - Assert output contains the provided stack text in the Stack Preferences section
  </action>
  <verify>
Run `node --test get-shit-done/bin/gsd-tools.test.js` and verify all generate-dev-preferences tests pass. Existing tests must also still pass.
  </verify>
  <done>
8 test cases for generate-dev-preferences covering: valid output, all dimensions, questionnaire source, CLAUDE_INSTRUCTIONS fallback, directory creation, error handling (missing file, malformed JSON), and custom stack option.
  </done>
</task>

<task type="auto">
  <name>Task 2: Tests for generate-claude-profile subcommand</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
Add a new `describe('generate-claude-profile', ...)` test suite to gsd-tools.test.js, following the same patterns as Task 1.

**Reuse** the MOCK_ANALYSIS fixture from the generate-dev-preferences test suite (or share a common fixture at the top of the file / in a shared setup).

**Test cases:**

1. **creates new CLAUDE.md when none exists**
   - Run `generate-claude-profile --analysis <path> --output <temp-output-path>` where output does not exist
   - Assert file is created
   - Assert file starts with `<!-- GSD:profile-start -->`
   - Assert file ends with `<!-- GSD:profile-end -->`
   - Assert file contains "Developer Profile" heading
   - Assert JSON output has `action: 'created'`

2. **updates existing CLAUDE.md between markers**
   - Create a temp CLAUDE.md with:
     ```
     # Project Config
     Some existing content.
     <!-- GSD:profile-start -->
     ## Old Profile
     Old content here.
     <!-- GSD:profile-end -->
     More existing content.
     ```
   - Run generate-claude-profile with `--output` pointing to this file
   - Assert "Project Config" and "Some existing content" are preserved
   - Assert "More existing content" is preserved
   - Assert old profile content is replaced
   - Assert new profile section contains dimension data from mock analysis
   - Assert JSON output has `action: 'updated'`

3. **appends profile section when CLAUDE.md has no markers**
   - Create a temp CLAUDE.md with just `# Project Config\nSome content.` (no markers)
   - Run generate-claude-profile
   - Assert original content is preserved at the top
   - Assert profile section is appended at the end
   - Assert markers are present in the appended section
   - Assert JSON output has `action: 'appended'`

4. **includes all 8 dimensions in profile section**
   - Use full mock analysis
   - Assert output contains all 8 dimension labels (Communication, Decisions, Explanations, Debugging, UX Philosophy, Vendor Choices, Frustrations, Learning)
   - Assert each has a rating and confidence

5. **--global flag changes output path to ~/.claude/CLAUDE.md**
   - Run with `--global` flag and `--output` (output should be ignored when global is set; or test that global takes precedence)
   - Assert JSON output has `is_global: true`
   - Assert `claude_md_path` contains `.claude/CLAUDE.md` pattern

6. **creates parent directories for global CLAUDE.md if needed**
   - Use `--global` with a test override that points to a temp nested path
   - Assert file is created (mkdirSync recursive worked)

7. **errors when analysis file not found**
   - Same pattern as dev-preferences error test
   - Assert non-zero exit and error message

8. **errors when analysis JSON lacks dimensions**
   - Write `{"profile_version": "1.0"}` (no dimensions key) to temp file
   - Assert error about missing dimensions

9. **preserves exact whitespace and content outside markers**
   - Create CLAUDE.md with complex content (multiple sections, code blocks, blank lines) plus markers
   - After update, assert byte-level preservation of content outside markers

**Testing strategy for --global:** Since the actual global path is `~/.claude/CLAUDE.md`, tests should use `--output` to redirect to a temp directory. The `--global` flag's path logic is tested separately by checking the JSON output's `is_global` field and `claude_md_path` value.
  </action>
  <verify>
Run `node --test get-shit-done/bin/gsd-tools.test.js` and verify all generate-claude-profile tests pass. All existing tests (Phase 1, Phase 2, and generate-dev-preferences) must also still pass.
  </verify>
  <done>
9 test cases for generate-claude-profile covering: create new, update between markers, append without markers, all dimensions, --global flag, directory creation, error handling (missing file, missing dimensions), and content preservation outside markers. All tests pass alongside existing suites.
  </done>
</task>

</tasks>

<verification>
- [ ] All generate-dev-preferences tests pass
- [ ] All generate-claude-profile tests pass
- [ ] All existing Phase 1 tests still pass
- [ ] All existing Phase 2 tests still pass
- [ ] `node --test get-shit-done/bin/gsd-tools.test.js` shows 0 failures
- [ ] Test fixtures use realistic analysis JSON matching profiler output schema
- [ ] Tests use temp directories for isolation (no side effects on real files)
</verification>

<success_criteria>
- 17 new test cases (8 for generate-dev-preferences, 9 for generate-claude-profile)
- All tests pass alongside existing Phase 1 and Phase 2 test suites
- Tests cover happy paths, edge cases (missing fields, no markers, questionnaire source), and error cases
- Test fixtures follow established Phase 2 test patterns (runGsdTools helper, temp dirs, mock data)
</success_criteria>

<output>
After completion, create `.planning/phases/03-profile-activation/03-03-SUMMARY.md`
</output>
