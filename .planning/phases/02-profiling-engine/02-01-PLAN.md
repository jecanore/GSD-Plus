---
phase: 02-profiling-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/references/user-profiling.md
  - agents/gsd-user-profiler.md
  - get-shit-done/references/model-profiles.md
autonomous: true

must_haves:
  truths:
    - "user-profiling.md defines detection heuristics, signal patterns, example quotes, and confidence scoring rules for all 8 behavioral dimensions"
    - "Each dimension has a spectrum of possible ratings, minimum evidence thresholds for HIGH/MEDIUM/LOW confidence, and evidence curation guidelines"
    - "gsd-user-profiler agent receives pre-extracted messages and applies the reference doc heuristics to produce a structured JSON analysis"
    - "Agent output schema includes per-dimension rating, confidence, evidence_count, evidence_quotes (with quote, session_id, project, signal), summary, and claude_instruction"
    - "Agent explicitly handles insufficient data by reporting confidence: LOW with 'insufficient data' note rather than guessing"
    - "Model profiles reference includes gsd-user-profiler with quality: opus, balanced: sonnet, budget: sonnet"
  artifacts:
    - path: "get-shit-done/references/user-profiling.md"
      provides: "8-dimension behavioral analysis rubric with detection heuristics and confidence scoring"
      contains: "Communication Style"
    - path: "agents/gsd-user-profiler.md"
      provides: "Agent definition for LLM-based behavioral profiling"
      contains: "gsd-user-profiler"
    - path: "get-shit-done/references/model-profiles.md"
      provides: "Model tier mapping for profiler agent"
      contains: "gsd-user-profiler"
  key_links:
    - from: "agents/gsd-user-profiler.md"
      to: "get-shit-done/references/user-profiling.md"
      via: "@reference file inclusion in agent context"
      pattern: "user-profiling.md"
    - from: "agents/gsd-user-profiler.md"
      to: "structured JSON output"
      via: "output schema definition in agent instructions"
      pattern: "dimensions.*rating.*confidence"
---

<objective>
Create the profiling reference document and agent definition that together form the behavioral analysis engine.

Purpose: The reference doc (`user-profiling.md`) defines WHAT to look for -- detection heuristics, signal patterns, confidence scoring rules, and evidence curation guidelines for all 8 behavioral dimensions. The agent (`gsd-user-profiler.md`) defines HOW to apply those heuristics -- receiving pre-extracted messages, applying the rubric, and producing structured JSON output. Together, they make profiling reproducible and auditable: same rubric + same data = comparable results.

Output: `user-profiling.md` reference doc, `gsd-user-profiler.md` agent definition, and updated `model-profiles.md` with the new agent entry.
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-profiling-engine/02-RESEARCH.md
@agents/gsd-codebase-mapper.md
@agents/gsd-phase-researcher.md
@get-shit-done/references/model-profiles.md
@get-shit-done/references/questioning.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create user-profiling reference document</name>
  <files>get-shit-done/references/user-profiling.md</files>
  <action>
Create `get-shit-done/references/user-profiling.md` -- the rubric document that the profiler agent references during analysis. This is the critical artifact because it encodes what the agent looks for, how it scores confidence, and what constitutes evidence.

Structure the document with these sections:

**1. Header and Purpose**
- Title: `# User Profiling: Behavioral Dimension Reference`
- State this document's role: rubric for LLM-based analysis, NOT a specification for code. The profiler agent reads this document and applies the heuristics to user messages.

**2. Evidence Standards (global rules)**
- Minimum evidence thresholds per confidence level:
  - HIGH: 10+ consistent signals across 2+ projects
  - MEDIUM: 5-9 signals OR consistent within 1 project only
  - LOW: fewer than 5 signals OR mixed/contradictory signals
- "Insufficient data" is a valid finding. If evidence is below LOW threshold, report "insufficient_data" as the rating with confidence "LOW" and note "Not enough evidence to determine pattern."
- Cross-project consistency: when a pattern appears in only one project, note it. When consistent across multiple projects, that increases confidence.
- Evidence curation guidelines:
  - Never include quotes containing patterns matching API keys (`sk-`, `pk_`, `Bearer`), passwords, tokens, or secrets
  - Truncate quotes to the behavioral signal (first 200 characters or the relevant sentence), not the full message
  - Prefer quotes demonstrating communication style over technical content
  - Skip messages that are session continuations ("This session is being continued...") or predominantly log output (>80% timestamps, [DEBUG], [INFO] patterns)

**3. Per-Dimension Sections (8 sections, one per dimension)**

For EACH of these 8 dimensions, write a section with this structure:

```
### Dimension N: [Name]

**What we're measuring:** [One sentence definition]

**Rating spectrum:**
- **[rating-1]:** [Description with behavioral indicators]
- **[rating-2]:** [Description with behavioral indicators]
- **[rating-3]:** [Description with behavioral indicators]
- **[rating-4]:** [Description with behavioral indicators]

**Signal patterns (what to look for in messages):**
1. [Specific signal with detection method]
2. [Specific signal with detection method]
3. [Specific signal with detection method]
4. [Specific signal with detection method]

**Confidence scoring for this dimension:**
- HIGH: [Specific threshold -- e.g., "10+ messages showing consistent pattern across 2+ projects"]
- MEDIUM: [Specific threshold]
- LOW: [Specific threshold]

**Example evidence quotes (illustrative):**
- [rating-1]: "[example quote]" -- Signal: [what this demonstrates]
- [rating-2]: "[example quote]" -- Signal: [what this demonstrates]
- [rating-3]: "[example quote]" -- Signal: [what this demonstrates]
```

The 8 dimensions and their rating spectrums (from research):

1. **Communication Style** -- terse-direct | conversational | detailed-structured | mixed
   - Signals: message length, formatting (headers, numbered lists), context preambles, imperative vs interrogative mood, code block usage

2. **Decision Speed** -- fast-intuitive | deliberate-informed | research-first | delegator
   - Signals: "just pick one" language, request for comparisons, "let me think about it", "what do you recommend?", immediate selection after options

3. **Explanation Depth** -- code-only | concise | detailed | educational
   - Signals: "just show me the code", "explain why", "teach me", "I know this part, skip the explanation", "what does X mean?"

4. **Debugging Approach** -- fix-first | diagnostic | hypothesis-driven | collaborative
   - Signals: error pasting without analysis, "why is this happening?", "I think the issue is...", "let's walk through this together"

5. **UX Philosophy** -- function-first | pragmatic | design-conscious | backend-focused
   - Signals: mentions of UI polish, animation, accessibility, "just make it work", design tool references, mobile-first mentions

6. **Vendor Philosophy** -- pragmatic-fast | conservative | thorough-evaluator | opinionated
   - Signals: "just use whatever", "is X the standard?", comparison requests, strong stated preferences ("I always use X")

7. **Frustration Triggers** -- scope-creep | instruction-adherence | verbosity | regression
   - Signals: repeated corrections, "I said...", "don't...", "why did you...", emotional language shifts, ALL CAPS, increased punctuation (!!!, ???)

8. **Learning Style** -- self-directed | guided | documentation-first | example-driven
   - Signals: "show me an example", "link me the docs", "explain this", "I'll figure it out", code-reading requests vs explanation requests

**4. Output Schema**
Include the full JSON schema the profiler agent must produce:

```json
{
  "profile_version": "1.0",
  "analyzed_at": "ISO-8601 timestamp",
  "data_source": "session_analysis",
  "projects_analyzed": ["project-name-1", "project-name-2"],
  "messages_analyzed": 150,
  "dimensions": {
    "communication_style": {
      "rating": "one of the spectrum values or 'insufficient_data'",
      "confidence": "HIGH | MEDIUM | LOW",
      "evidence_count": 23,
      "cross_project_consistent": true,
      "evidence_quotes": [
        {
          "quote": "First 200 chars of relevant message",
          "session_id": "abc123",
          "project": "project-name",
          "signal": "What this quote demonstrates about the dimension"
        }
      ],
      "summary": "1-2 sentence behavioral summary for this dimension",
      "claude_instruction": "Specific instruction for Claude when interacting with this developer"
    }
  }
}
```

Keep evidence_quotes to 2-4 representative quotes per dimension (not all evidence).

**5. Anti-Patterns**
- Do NOT invent dimensions beyond the 8 defined here
- Do NOT report HIGH confidence from fewer than 10 signals
- Do NOT include quotes containing sensitive information
- Do NOT confuse task-appropriate behavior with personality (e.g., short message for a simple bug fix is not "terse communication style")
- Do NOT rate based on a single project's domain patterns (e.g., structured specs for real estate may not reflect general communication style)
  </action>
  <verify>
Verify the file exists and contains all 8 dimension sections: `grep -c "### Dimension" get-shit-done/references/user-profiling.md` should return 8. Verify the output schema section exists: `grep "profile_version" get-shit-done/references/user-profiling.md` should return a match. Verify evidence standards section: `grep "Evidence Standards" get-shit-done/references/user-profiling.md`.
  </verify>
  <done>
`user-profiling.md` exists with all 8 behavioral dimensions defined, each with rating spectrum, signal patterns, confidence scoring rules, and example evidence quotes. Global evidence standards section defines minimum thresholds and curation guidelines. Output schema section defines the exact JSON structure the profiler must produce. Anti-patterns section prevents common LLM analysis failures.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create gsd-user-profiler agent definition and update model profiles</name>
  <files>agents/gsd-user-profiler.md, get-shit-done/references/model-profiles.md</files>
  <action>
**Part A: Create `agents/gsd-user-profiler.md`**

Follow the established agent definition pattern (YAML frontmatter with name, description, tools, color; then structured sections with XML tags).

Frontmatter:
```yaml
---
name: gsd-user-profiler
description: Analyzes developer session messages across 8 behavioral dimensions to produce an evidence-backed profile with calibrated confidence scoring. Spawned by /gsd:profile-user orchestrator.
tools: Read, Bash, Grep, Glob
color: magenta
---
```

Note: This agent does NOT need Write, WebSearch, or WebFetch. It reads pre-extracted messages, applies heuristics, and returns structured JSON to the orchestrator. The orchestrator handles file writing.

Structure (following established patterns from gsd-codebase-mapper.md, gsd-phase-researcher.md):

**`<role>`**
You are a GSD user profiler. You analyze developer messages across 8 behavioral dimensions using a reference rubric and produce a structured JSON analysis.

Spawned by `/gsd:profile-user` orchestrator with:
- A path to a JSONL file containing pre-extracted, pre-sampled user messages (from `profile-sample` subcommand)
- The user-profiling reference doc loaded as context

Your job: Read messages, apply the heuristics from the reference doc, score each dimension, collect evidence, and return the structured analysis JSON. You do NOT write any files -- the orchestrator handles that.

**`<input>`**
Describe what the agent receives:
- `@get-shit-done/references/user-profiling.md` -- the rubric (loaded as context)
- A JSONL file path (provided by orchestrator) -- each line is `{ sessionId, projectPath, timestamp, content, projectName }`
- The JSONL file contains pre-sampled messages (100-150 messages, project-proportionally sampled, each truncated to 500 chars)

**`<process>`**
Step-by-step analysis process:

1. **Read all messages** from the provided JSONL file path using Read tool or `cat` via Bash.
2. **Catalog messages by project** -- group messages by `projectName` to track cross-project patterns.
3. **For each of the 8 dimensions** (in order defined in the reference doc):
   a. Scan all messages for signals defined in the reference doc for that dimension
   b. Count signals found (evidence_count)
   c. Check cross-project consistency (same pattern in 2+ projects?)
   d. Select 2-4 representative quotes (following evidence curation guidelines -- no secrets, truncate to signal, prefer behavioral over technical)
   e. Determine rating based on the predominant signal pattern
   f. Determine confidence based on evidence_count and cross-project consistency per the reference doc thresholds
   g. Write summary (1-2 sentences describing the observed pattern)
   h. Write claude_instruction (specific, actionable instruction for Claude when interacting with this developer)
4. **Apply confirmation bias check:** If all 8 dimensions are HIGH confidence and the total message count is under 50, reduce all to MEDIUM. If under 20 messages total, reduce all to LOW. This is a safety mechanism against LLM over-pattern-matching.
5. **Assemble the output JSON** per the schema defined in user-profiling.md.

**`<output>`**
The agent returns the structured JSON analysis object to the orchestrator. The JSON follows the exact schema in user-profiling.md. The orchestrator then passes this JSON to `write-profile` to render USER-PROFILE.md.

Format:
```
<analysis>
{
  "profile_version": "1.0",
  ...full JSON per schema...
}
</analysis>
```

The orchestrator extracts JSON from between `<analysis>` tags.

**`<constraints>`**
- NEVER invent dimensions beyond the 8 in the reference doc
- NEVER report HIGH confidence from fewer than 10 signals
- NEVER include quotes containing sensitive patterns (API keys, passwords, tokens)
- When evidence is insufficient, use rating: "insufficient_data" with confidence: "LOW"
- Do not confuse task-appropriate behavior (short message for simple bug) with personality trait (terse communicator)
- Weight natural language messages higher than pasted logs or context dumps
- When a pattern appears in only one project, explicitly note cross_project_consistent: false

**Part B: Update `get-shit-done/references/model-profiles.md`**

Add `gsd-user-profiler` to the model profiles table. Insert a new row after `gsd-plan-checker`:

```
| gsd-user-profiler | opus | sonnet | sonnet |
```

Rationale: Behavioral analysis requires nuanced reasoning (opus for quality), but can be done well by sonnet for balanced/budget since the reference doc provides the rubric. Per research recommendation.
  </action>
  <verify>
1. Verify agent file exists with correct frontmatter: `head -6 agents/gsd-user-profiler.md` should show name, description, tools, color.
2. Verify agent references the user-profiling doc: `grep "user-profiling.md" agents/gsd-user-profiler.md` should match.
3. Verify agent defines output schema: `grep "analysis" agents/gsd-user-profiler.md` should match the output tags.
4. Verify model profiles updated: `grep "gsd-user-profiler" get-shit-done/references/model-profiles.md` should show the new row.
5. Verify all 8 dimensions are referenced in the agent: `grep -c "dimension" agents/gsd-user-profiler.md` should be > 0.
  </verify>
  <done>
`gsd-user-profiler.md` agent exists with YAML frontmatter, role definition, input specification, step-by-step analysis process, structured JSON output format with `<analysis>` tags, and constraints section preventing common profiling failures. Agent references `user-profiling.md` as its rubric. `model-profiles.md` includes `gsd-user-profiler` entry with quality: opus, balanced: sonnet, budget: sonnet.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 02-01 deliverables:

1. **Reference doc exists:** `test -f get-shit-done/references/user-profiling.md && echo "OK"`
2. **All 8 dimensions:** `grep -c "### Dimension" get-shit-done/references/user-profiling.md` returns 8
3. **Output schema defined:** `grep "profile_version" get-shit-done/references/user-profiling.md` matches
4. **Evidence standards:** `grep "Evidence Standards" get-shit-done/references/user-profiling.md` matches
5. **Agent exists:** `test -f agents/gsd-user-profiler.md && echo "OK"`
6. **Agent references rubric:** `grep "user-profiling.md" agents/gsd-user-profiler.md` matches
7. **Agent output format:** `grep "<analysis>" agents/gsd-user-profiler.md` matches
8. **Model profiles updated:** `grep "gsd-user-profiler" get-shit-done/references/model-profiles.md` matches
9. **No broken cross-references:** All file paths mentioned in agent context section exist
</verification>

<success_criteria>
- `user-profiling.md` is a complete rubric covering all 8 dimensions with detection heuristics, rating spectrums, confidence rules, and evidence curation guidelines
- `gsd-user-profiler.md` follows established agent patterns and references the rubric
- Agent output schema matches the JSON structure defined in the reference doc
- Confirmation bias mitigation is built into both the reference doc thresholds and the agent process
- Model profiles include the new agent with appropriate tier mappings
- All artifacts are self-consistent (agent references doc, doc defines schema agent uses)
</success_criteria>

<output>
After completion, create `.planning/phases/02-profiling-engine/02-01-SUMMARY.md`
</output>
