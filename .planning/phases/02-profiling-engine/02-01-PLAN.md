---
phase: 02-profiling-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/references/user-profiling.md
  - agents/gsd-user-profiler.md
  - get-shit-done/references/model-profiles.md
autonomous: true

must_haves:
  truths:
    - "User-profiling reference doc defines detection heuristics, signal patterns, example quotes, and confidence scoring rules for all 8 behavioral dimensions"
    - "gsd-user-profiler agent receives extracted messages and applies reference doc heuristics to produce a structured JSON analysis across all 8 dimensions"
    - "Each dimension's confidence scoring rules specify minimum evidence thresholds: HIGH requires 10+ signals across 2+ projects, MEDIUM requires 5-9 signals, LOW requires fewer"
    - "Reference doc includes sensitive content exclusion guidelines for evidence curation"
    - "Model profiles map gsd-user-profiler to quality: opus, balanced: sonnet, budget: sonnet"
  artifacts:
    - path: "get-shit-done/references/user-profiling.md"
      provides: "8-dimension detection heuristics reference doc"
      contains: "Communication Style"
    - path: "agents/gsd-user-profiler.md"
      provides: "Profiler agent definition"
      contains: "gsd-user-profiler"
    - path: "get-shit-done/references/model-profiles.md"
      provides: "Updated model profiles with gsd-user-profiler entry"
      contains: "gsd-user-profiler"
  key_links:
    - from: "agents/gsd-user-profiler.md"
      to: "get-shit-done/references/user-profiling.md"
      via: "@reference file inclusion"
      pattern: "user-profiling.md"
    - from: "get-shit-done/references/model-profiles.md"
      to: "agents/gsd-user-profiler.md"
      via: "agent-to-model mapping table row"
      pattern: "gsd-user-profiler"
---

<objective>
Create the foundational knowledge artifacts for the profiling engine: the user-profiling reference document that defines detection heuristics and scoring rules for all 8 behavioral dimensions, the gsd-user-profiler agent that applies those heuristics to extracted session messages, and the model profiles update to map the new agent.

Purpose: The reference doc IS the analysis rubric -- without it, the profiler agent would hallucinate patterns and apply inconsistent scoring. The agent definition IS the prompt that drives analysis. These two artifacts together make profiling reproducible and auditable. The model profiles update ensures the agent is dispatched at the correct quality tier.

Output: Three files -- `get-shit-done/references/user-profiling.md` (reference doc), `agents/gsd-user-profiler.md` (agent), `get-shit-done/references/model-profiles.md` (updated).
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-profiling-engine/02-RESEARCH.md
@.planning/phases/02-profiling-engine/02-CONTEXT.md
@agents/gsd-codebase-mapper.md
@get-shit-done/references/model-profiles.md
@get-shit-done/references/questioning.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create user-profiling reference document with 8-dimension detection heuristics</name>
  <files>get-shit-done/references/user-profiling.md</files>
  <action>
Create `get-shit-done/references/user-profiling.md` -- the rubric that the gsd-user-profiler agent applies when analyzing session messages. This is the most critical artifact in Phase 2 because it determines profiling accuracy and reproducibility.

Use `/technical-writing` skill and `sequential-thinking` MCP when crafting this document -- per user decision.

**Document structure:**

1. **Header section** with purpose statement: "This reference document defines detection heuristics for behavioral profiling. The gsd-user-profiler agent applies these rules when analyzing extracted session messages. Do not invent dimensions or scoring rules beyond what is defined here."

2. **For each of the 8 dimensions**, create a section with:

   a. **Dimension name and ID** (e.g., `### 1. Communication Style` / `dimension_id: communication_style`)
   b. **What we're measuring** -- one sentence describing the behavioral axis
   c. **Rating spectrum** -- the possible ratings with brief descriptions:
      - `communication_style`: terse-direct | conversational | detailed-structured | mixed
      - `decision_speed`: fast-intuitive | deliberate-informed | research-first | delegator
      - `explanation_depth`: code-only | concise | detailed | educational
      - `debugging_approach`: fix-first | diagnostic | hypothesis-driven | collaborative
      - `ux_philosophy`: function-first | pragmatic | design-conscious | backend-focused
      - `vendor_philosophy`: pragmatic-fast | conservative | thorough-evaluator | opinionated
      - `frustration_triggers`: scope-creep | instruction-adherence | verbosity | regression
      - `learning_style`: self-directed | guided | documentation-first | example-driven
   d. **Signal patterns** -- 4-6 specific observable signals the agent should look for in messages (e.g., average message length, ratio of imperative to interrogative sentences, presence of structured formatting)
   e. **Detection heuristics** -- numbered, concrete rules for classifying (e.g., "If average message length < 50 words AND predominantly imperative mood -> terse-direct")
   f. **Confidence scoring** -- threshold-based rules per the user decision:
      - HIGH: 10+ messages showing consistent pattern, same pattern across 2+ projects
      - MEDIUM: 5-9 messages OR pattern consistent within 1 project only
      - LOW: <5 messages OR mixed signals (contradictory patterns observed)
      - UNSCORED: 0 messages with relevant signals
   g. **Example quotes** -- 2-3 example quotes illustrating each rating on the spectrum (these are fictional examples for the rubric, not from real sessions)
   h. **Context-dependent patterns** -- guidance for when a dimension shows different patterns across project types (per user decision: report the split, e.g., "context-dependent: terse in CLI projects, detailed in frontend")

3. **Evidence curation section:**
   - Combined format per user decision: **Signal:** [pattern interpretation] / **Example:** "[trimmed quote]" -- project: [name]
   - 3 evidence quotes per dimension target (24 total)
   - Quote truncation guideline: trim to behavioral signal, approximately 100 characters
   - Project attribution on each quote
   - Sensitive content exclusion rules:
     - Layer 1 (profiler): Never select quotes containing patterns matching: `sk-`, `Bearer `, `password`, `secret`, `token`, `api_key`, `API_KEY`, full absolute file paths with usernames
     - Note: Layer 2 (regex filter in write-profile) provides defense in depth -- profiler should still avoid selecting sensitive quotes
   - When sensitive content is found and excluded, report as metadata: `{ sensitive_excluded: [{ type, count }] }`

4. **Recency weighting section:**
   - Guideline: recent sessions (last 30 days) weighted ~3x over older sessions
   - Formula at Claude's discretion but document whatever is chosen
   - Rationale: developer styles evolve, recent behavior is more accurate

5. **Thin data handling section:**
   - Below 50 genuine user messages: hybrid mode (analyze available + supplement with questionnaire)
   - Below 20 messages: recommend questionnaire fallback, all dimensions LOW confidence
   - Above 50 messages: full analysis, questionnaire optional
   - When data is insufficient for a dimension: report confidence as UNSCORED with note "insufficient data -- no clear signals detected"

6. **Output schema section** -- define the exact JSON structure the profiler agent must return:
   ```json
   {
     "profile_version": "1.0",
     "analyzed_at": "ISO-8601",
     "data_source": "session_analysis",
     "projects_analyzed": ["string"],
     "messages_analyzed": 0,
     "message_threshold": "full|hybrid|insufficient",
     "sensitive_excluded": [{ "type": "string", "count": 0 }],
     "dimensions": {
       "communication_style": {
         "rating": "string",
         "confidence": "HIGH|MEDIUM|LOW|UNSCORED",
         "evidence_count": 0,
         "cross_project_consistent": true,
         "evidence_quotes": [
           {
             "signal": "string",
             "quote": "string (~100 chars)",
             "project": "string"
           }
         ],
         "summary": "string",
         "claude_instruction": "string"
       }
     }
   }
   ```
   - Note that `claude_instruction` must be written in imperative form directed at Claude: "Match this developer's structured communication" NOT "You tend to provide structured context"
   - Per user decision: profile is an instruction document for Claude's consumption

7. **Cross-project consistency section** -- how to assess and report when dimensions show different patterns across projects (per user decision: report the split rather than forcing a single rating, Phase 3 resolves with user)
  </action>
  <verify>
Verify the file exists and contains all 8 dimension sections:
```bash
node -e "
const fs = require('fs');
const content = fs.readFileSync('get-shit-done/references/user-profiling.md', 'utf-8');
const dims = ['communication_style', 'decision_speed', 'explanation_depth', 'debugging_approach', 'ux_philosophy', 'vendor_philosophy', 'frustration_triggers', 'learning_style'];
const found = dims.filter(d => content.includes(d));
console.log(found.length === 8 ? 'PASS: All 8 dimensions present' : 'FAIL: Missing ' + dims.filter(d => !found.includes(d)).join(', '));
console.log(content.includes('confidence') ? 'PASS: Confidence scoring present' : 'FAIL: No confidence scoring');
console.log(content.includes('sensitive') ? 'PASS: Sensitive content rules present' : 'FAIL: No sensitive content rules');
"
```
  </verify>
  <done>
User-profiling reference document exists at `get-shit-done/references/user-profiling.md` with all 8 dimension sections, each containing: rating spectrum, signal patterns, detection heuristics, confidence scoring thresholds, and example quotes. Evidence curation rules, recency weighting, thin data handling, output schema, and cross-project consistency guidance are all present.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create gsd-user-profiler agent definition and update model profiles</name>
  <files>agents/gsd-user-profiler.md, get-shit-done/references/model-profiles.md</files>
  <action>
**Part A: Create `agents/gsd-user-profiler.md`**

Follow the established GSD agent convention (see `agents/gsd-codebase-mapper.md` for format: YAML frontmatter with name/description/tools/color, then role/process sections in XML tags).

**Frontmatter:**
```yaml
---
name: gsd-user-profiler
description: Analyzes extracted session messages across 8 behavioral dimensions to produce a scored developer profile with confidence levels and evidence. Spawned by profile orchestration workflows.
tools: Read
color: magenta
---
```

**Role section (`<role>`):**
- "You are a GSD user profiler. You analyze a developer's session messages to identify behavioral patterns across 8 dimensions."
- "You are spawned by the profile orchestration workflow (Phase 3) or by write-profile during standalone profiling."
- "Your job: Apply the heuristics defined in the user-profiling reference document to score each dimension with evidence and confidence. Return structured JSON analysis."
- "CRITICAL: You must apply the rubric defined in the reference document. Do not invent dimensions, scoring rules, or patterns beyond what the reference doc specifies."

**Input section (`<input>`):**
Describe what the agent receives:
- Extracted session messages as JSONL content (from profile-sample output)
- Each message has: `{ sessionId, projectPath, projectName, timestamp, content }`
- Messages are already filtered (genuine user messages only) and truncated (max 500 chars for profiling)
- Messages are project-proportionally sampled with recency weighting applied

**Reference section:**
- `@get-shit-done/references/user-profiling.md` -- the detection heuristics rubric

**Process section (`<process>`):**
1. Read the reference document to load dimension definitions and scoring rules
2. Read all provided session messages
3. For each of the 8 dimensions:
   a. Scan messages for signal patterns defined in the reference doc
   b. Count evidence signals found
   c. Select up to 3 representative quotes per dimension (per evidence curation rules)
   d. Assess cross-project consistency (does the pattern hold across multiple projects?)
   e. Apply confidence scoring thresholds from the reference doc
   f. Write a summary of the observed pattern
   g. Write a claude_instruction in imperative form for Claude's consumption
4. Check all selected quotes for sensitive content (Layer 1 filtering per reference doc)
5. Report any sensitive content found and excluded as metadata
6. Return the complete analysis as JSON wrapped in `<analysis>` tags

**Output section (`<output>`):**
- Must return JSON matching the exact schema defined in the reference doc's output schema section
- JSON must be wrapped in `<analysis>` tags for reliable extraction by the orchestrator
- Format: `<analysis>{ ... JSON ... }</analysis>`
- If data is insufficient for all dimensions: still return the full schema with UNSCORED dimensions noting "insufficient data"

**Constraints section (`<constraints>`):**
- Never select quotes containing sensitive patterns (sk-, Bearer, password, secret, token, api_key, full file paths)
- Never invent evidence or fabricate quotes
- Never rate a dimension HIGH without 10+ signals across 2+ projects
- Weight recent messages (~3x for last 30 days) per reference doc guidelines
- Report context-dependent splits rather than forcing a single rating when contradictory signals exist across projects
- Claude_instruction fields must be imperative directives, not descriptions (per user decision: profile is an instruction document)

**Part B: Update `get-shit-done/references/model-profiles.md`**

Add a new row to the Profile Definitions table:

| gsd-user-profiler | opus | sonnet | sonnet |

Place it alphabetically among existing entries (after gsd-planner, before gsd-project-researcher based on sort order, or after gsd-plan-checker based on the existing table order -- match the existing sort convention).

Add a rationale entry at the bottom:

**Why Opus for gsd-user-profiler in quality?**
Behavioral analysis from session messages requires nuanced pattern recognition, contextual reasoning about communication style, and careful confidence calibration. Opus handles the subtlety; Sonnet is sufficient for balanced/budget since the reference doc rubric constrains the analysis space.
  </action>
  <verify>
```bash
# Verify agent file exists with correct frontmatter
node -e "
const fs = require('fs');
const agent = fs.readFileSync('agents/gsd-user-profiler.md', 'utf-8');
console.log(agent.includes('name: gsd-user-profiler') ? 'PASS: Agent name' : 'FAIL: Agent name');
console.log(agent.includes('user-profiling.md') ? 'PASS: References user-profiling.md' : 'FAIL: Missing reference');
console.log(agent.includes('<analysis>') ? 'PASS: Output format defined' : 'FAIL: Missing output format');
"

# Verify model profiles updated
node -e "
const fs = require('fs');
const mp = fs.readFileSync('get-shit-done/references/model-profiles.md', 'utf-8');
console.log(mp.includes('gsd-user-profiler') ? 'PASS: Model profile entry exists' : 'FAIL: Missing model profile entry');
"
```
  </verify>
  <done>
`agents/gsd-user-profiler.md` exists with YAML frontmatter, role definition, input/output specs, process steps, reference to user-profiling.md, and constraints. `get-shit-done/references/model-profiles.md` includes gsd-user-profiler row (opus/sonnet/sonnet) and rationale.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 02-01 deliverables:

1. **Reference doc exists and covers all dimensions:**
   `grep -c 'dimension_id:' get-shit-done/references/user-profiling.md` -- should return 8
2. **Reference doc has confidence scoring:**
   `grep -c 'HIGH\|MEDIUM\|LOW' get-shit-done/references/user-profiling.md` -- should be > 0
3. **Agent definition exists:**
   `test -f agents/gsd-user-profiler.md && echo "PASS" || echo "FAIL"`
4. **Agent references rubric:**
   `grep 'user-profiling.md' agents/gsd-user-profiler.md` -- should find reference
5. **Model profiles updated:**
   `grep 'gsd-user-profiler' get-shit-done/references/model-profiles.md` -- should find entry
6. **Output schema defined in reference doc:**
   `grep 'profile_version' get-shit-done/references/user-profiling.md` -- should find schema
</verification>

<success_criteria>
- User-profiling reference doc defines all 8 dimensions with detection heuristics, signal patterns, confidence scoring rules, and example quotes
- Evidence curation rules specify combined format (Signal + Example), 3 quotes per dimension, sensitive content exclusion
- Output schema is fully defined with all required fields
- gsd-user-profiler agent references the rubric doc, defines input/output contracts, and includes constraints
- Model profiles table includes gsd-user-profiler with quality: opus, balanced: sonnet, budget: sonnet
</success_criteria>

<output>
After completion, create `.planning/phases/02-profiling-engine/02-01-SUMMARY.md`
</output>
