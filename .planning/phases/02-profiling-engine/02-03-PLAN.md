---
phase: 02-profiling-engine
plan: 03
type: execute
wave: 2
depends_on:
  - 02-01
  - 02-02
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "Running `gsd-tools.js profile-questionnaire` presents 8 sequential prompts, one per behavioral dimension, and outputs a profiler-compatible JSON file"
    - "Questionnaire-generated JSON has the exact same schema as session-analysis JSON, with all 8 dimensions populated"
    - "All questionnaire-derived dimensions have confidence: LOW and data_source: questionnaire"
    - "Questionnaire JSON can be passed directly to `write-profile` to produce USER-PROFILE.md"
    - "Tests cover profile-sample (proportional sampling, message truncation, project interleaving), write-profile (template rendering, missing dimensions, directory creation), and profile-questionnaire (output schema compatibility)"
    - "All existing tests still pass after adding new test suites"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "profile-questionnaire subcommand with 8 dimension prompts"
      contains: "cmdProfileQuestionnaire"
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Tests for profile-sample, write-profile, and profile-questionnaire"
      contains: "profile-sample"
  key_links:
    - from: "main() switch"
      to: "cmdProfileQuestionnaire()"
      via: "case 'profile-questionnaire' dispatch"
      pattern: "case 'profile-questionnaire'"
    - from: "cmdProfileQuestionnaire()"
      to: "PROFILING_QUESTIONS array"
      via: "question definitions matching 8 dimensions"
      pattern: "PROFILING_QUESTIONS"
    - from: "profile-questionnaire output"
      to: "write-profile input"
      via: "same JSON schema (profile_version, dimensions, etc.)"
      pattern: "profile_version"
---

<objective>
Build the questionnaire fallback for users without session data and add comprehensive tests for all Phase 2 gsd-tools functionality.

Purpose: The questionnaire (PROF-05) ensures every user can get a profile, even without session history. It produces the exact same JSON schema as session analysis, so downstream consumers (write-profile, CLAUDE.md generation, /dev-preferences) do not need to know which path generated the profile. Tests validate all three new subcommands (profile-sample, write-profile, profile-questionnaire) to prevent regression as future phases build on them.

Output: `gsd-tools.js` extended with `profile-questionnaire` subcommand and `PROFILING_QUESTIONS` data. `gsd-tools.test.js` extended with test suites for all Phase 2 subcommands.
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-profiling-engine/02-RESEARCH.md
@.planning/phases/02-profiling-engine/02-01-SUMMARY.md
@.planning/phases/02-profiling-engine/02-02-SUMMARY.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/bin/gsd-tools.test.js
@get-shit-done/references/user-profiling.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement profile-questionnaire subcommand</name>
  <files>get-shit-done/bin/gsd-tools.js</files>
  <action>
Add the `PROFILING_QUESTIONS` constant and `cmdProfileQuestionnaire` function to gsd-tools.js.

**PROFILING_QUESTIONS constant**

Place this near the other constants/helpers in the session pipeline section. This array defines the 8 dimension questions with their option-to-rating mappings (from research code example):

```javascript
const PROFILING_QUESTIONS = [
  {
    dimension: 'communication_style',
    header: 'Communication Style',
    question: 'When you ask Claude to build something, how much context do you typically provide?',
    options: [
      { label: 'Minimal -- "fix the bug", "add dark mode"', rating: 'terse-direct' },
      { label: 'Some context -- explain what and why in a paragraph', rating: 'conversational' },
      { label: 'Detailed specs -- headers, numbered lists, problem analysis', rating: 'detailed-structured' },
      { label: 'It depends on the task', rating: 'mixed' },
    ],
  },
  {
    dimension: 'decision_speed',
    header: 'Decision Making',
    question: 'When Claude presents you with multiple options (e.g., library choices), how do you typically decide?',
    options: [
      { label: 'Pick quickly based on gut or experience', rating: 'fast-intuitive' },
      { label: 'Ask for a comparison, then decide', rating: 'deliberate-informed' },
      { label: 'Research independently before deciding', rating: 'research-first' },
      { label: 'Let Claude recommend, I trust the suggestion', rating: 'delegator' },
    ],
  },
  {
    dimension: 'explanation_depth',
    header: 'Explanation Preferences',
    question: 'When Claude explains something, how much detail do you want?',
    options: [
      { label: 'Just the code, minimal explanation', rating: 'code-only' },
      { label: 'Brief explanation with code', rating: 'concise' },
      { label: 'Detailed walkthrough of the approach and code', rating: 'detailed' },
      { label: 'Deep dive -- teach me the concepts behind it', rating: 'educational' },
    ],
  },
  {
    dimension: 'debugging_approach',
    header: 'Debugging Style',
    question: 'When something breaks, how do you typically approach debugging with Claude?',
    options: [
      { label: 'Paste the error and say "fix it"', rating: 'fix-first' },
      { label: 'Share error + context, ask for diagnosis', rating: 'diagnostic' },
      { label: 'Investigate myself first, then ask Claude about specific theories', rating: 'hypothesis-driven' },
      { label: 'Walk through the code together step by step', rating: 'collaborative' },
    ],
  },
  {
    dimension: 'ux_philosophy',
    header: 'UX Philosophy',
    question: 'When building user-facing features, what do you prioritize?',
    options: [
      { label: 'Get it working first, polish later', rating: 'function-first' },
      { label: 'Basic usability from the start, nothing ugly', rating: 'pragmatic' },
      { label: 'Design and UX are as important as functionality', rating: 'design-conscious' },
      { label: 'I mostly build backend/CLI -- UX is minimal', rating: 'backend-focused' },
    ],
  },
  {
    dimension: 'vendor_philosophy',
    header: 'Library & Vendor Choices',
    question: 'When choosing libraries or services, what is your typical approach?',
    options: [
      { label: 'Use what Claude suggests -- speed matters', rating: 'pragmatic-fast' },
      { label: 'Prefer well-known, battle-tested options', rating: 'conservative' },
      { label: 'Research alternatives, read docs, compare', rating: 'thorough-evaluator' },
      { label: 'Strong opinions -- I know what I like', rating: 'opinionated' },
    ],
  },
  {
    dimension: 'frustration_triggers',
    header: 'Frustration Triggers',
    question: 'What frustrates you most when working with AI coding assistants?',
    options: [
      { label: 'Doing things I did not ask for', rating: 'scope-creep' },
      { label: 'Not following instructions precisely', rating: 'instruction-adherence' },
      { label: 'Over-explaining or being too verbose', rating: 'verbosity' },
      { label: 'Breaking working code while fixing something else', rating: 'regression' },
    ],
  },
  {
    dimension: 'learning_style',
    header: 'Learning Preferences',
    question: 'When you encounter something new in your codebase, how do you prefer to learn about it?',
    options: [
      { label: 'Read the code directly -- I figure it out', rating: 'self-directed' },
      { label: 'Ask Claude to explain the relevant parts', rating: 'guided' },
      { label: 'Read official docs and tutorials first', rating: 'documentation-first' },
      { label: 'See a working example, then modify it', rating: 'example-driven' },
    ],
  },
];
```

**`async function cmdProfileQuestionnaire(options, raw)`**

Parameters:
- `options`: `{ outputPath: string|null, answers: string|null }` -- `answers` is a comma-separated string of option indices (1-based) for non-interactive/test mode. Example: `"1,2,3,4,1,2,3,4"` means pick option 1 for Q1, option 2 for Q2, etc.
- `raw`: boolean

Logic:

1. If `options.answers` is provided (non-interactive mode for testing and agent use):
   - Parse: `const selections = options.answers.split(',').map(s => parseInt(s.trim(), 10));`
   - Validate length equals PROFILING_QUESTIONS.length (8). If not: `error('Expected 8 answers (one per dimension), got ' + selections.length)`
   - Validate each is 1-4. If any invalid: `error('Each answer must be 1-4')`

2. If `options.answers` is NOT provided (interactive mode):
   - This subcommand is designed to be called by the orchestrator agent which uses AskUserQuestion. In non-orchestrator mode, print each question with numbered options to stdout and read from stdin using readline.
   - Create readline interface: `const rl = readline.createInterface({ input: process.stdin, output: process.stderr });`
   - For each question in PROFILING_QUESTIONS:
     a. Print header and question to stderr
     b. Print numbered options (1-4) to stderr
     c. Read answer via `rl.question('Your choice (1-4): ')`
     d. Validate and store
   - Close readline interface

3. Build profile JSON from answers:
   ```javascript
   const dimensions = {};
   for (let i = 0; i < PROFILING_QUESTIONS.length; i++) {
     const q = PROFILING_QUESTIONS[i];
     const selectedIdx = selections[i] - 1; // 0-based
     const selected = q.options[selectedIdx];
     dimensions[q.dimension] = {
       rating: selected.rating,
       confidence: 'LOW',
       evidence_count: 1,
       cross_project_consistent: false,
       evidence_quotes: [{
         quote: selected.label,
         session_id: 'questionnaire',
         project: 'self-report',
         signal: `Self-reported: "${q.question}" -> "${selected.label}"`
       }],
       summary: `Self-reported as "${selected.label}" via questionnaire.`,
       claude_instruction: generateClaudeInstruction(q.dimension, selected.rating),
     };
   }
   ```

4. The `generateClaudeInstruction` helper function maps dimension+rating to a specific Claude instruction. Define this as a helper:
   ```javascript
   function generateClaudeInstruction(dimension, rating) {
     const instructions = {
       communication_style: {
         'terse-direct': 'Keep responses concise. Match the developer\'s direct style -- no unnecessary preamble.',
         'conversational': 'Use a conversational tone. Explain reasoning briefly alongside code.',
         'detailed-structured': 'Use headers, numbered lists, and structured format. Acknowledge context before responding.',
         'mixed': 'Adapt response length to task complexity -- brief for simple tasks, detailed for complex ones.',
       },
       decision_speed: {
         'fast-intuitive': 'Present a clear recommendation first. Only elaborate if asked.',
         'deliberate-informed': 'Present 2-3 options with brief tradeoffs. Let the developer choose.',
         'research-first': 'Provide thorough analysis with links to docs and alternatives before recommending.',
         'delegator': 'Make confident recommendations. State your choice and reasoning succinctly.',
       },
       explanation_depth: {
         'code-only': 'Lead with code. Add comments in code rather than prose explanations.',
         'concise': 'Brief explanation (2-3 sentences) followed by code.',
         'detailed': 'Walk through the approach step by step before showing code.',
         'educational': 'Teach the underlying concepts. Explain not just how, but why.',
       },
       debugging_approach: {
         'fix-first': 'Provide the fix immediately. Explain the cause briefly after the fix.',
         'diagnostic': 'Diagnose the root cause first, then provide the fix with explanation.',
         'hypothesis-driven': 'Engage with the developer\'s theories. Confirm or redirect based on evidence.',
         'collaborative': 'Walk through the debugging process step by step together.',
       },
       ux_philosophy: {
         'function-first': 'Prioritize working functionality. Skip UI polish unless asked.',
         'pragmatic': 'Include basic styling and usability. Nothing ugly, nothing fancy.',
         'design-conscious': 'Consider UX implications. Suggest design improvements proactively.',
         'backend-focused': 'Focus on API design, data modeling, and system architecture.',
       },
       vendor_philosophy: {
         'pragmatic-fast': 'Recommend the most common/popular option. Don\'t present alternatives unless asked.',
         'conservative': 'Recommend well-established, battle-tested libraries with large communities.',
         'thorough-evaluator': 'Present comparison tables with alternatives, tradeoffs, and documentation links.',
         'opinionated': 'Ask about preferences before suggesting. Respect stated library/tool choices.',
       },
       frustration_triggers: {
         'scope-creep': 'Do exactly what was asked. Never add unrequested features or refactoring.',
         'instruction-adherence': 'Follow instructions precisely. When deviating, explain why first.',
         'verbosity': 'Be concise. Avoid repeating what the developer already said.',
         'regression': 'Before modifying, verify existing tests pass. After changes, run affected tests.',
       },
       learning_style: {
         'self-directed': 'Point to relevant files and let the developer explore. Minimal hand-holding.',
         'guided': 'Explain the relevant parts when asked. Provide focused walkthroughs.',
         'documentation-first': 'Link to official docs. Reference documentation in explanations.',
         'example-driven': 'Show working examples first. Let the developer modify and learn by doing.',
       },
     };
     return (instructions[dimension] && instructions[dimension][rating])
       || `Adapt to the developer's ${dimension.replace(/_/g, ' ')} preference: ${rating}.`;
   }
   ```

5. Assemble full profile JSON:
   ```javascript
   const profile = {
     profile_version: '1.0',
     analyzed_at: new Date().toISOString(),
     data_source: 'questionnaire',
     projects_analyzed: [],
     messages_analyzed: 0,
     dimensions,
   };
   ```

6. Write to temp file:
   ```javascript
   const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'gsd-profile-'));
   const outputPath = path.join(tmpDir, 'questionnaire-profile.json');
   fs.writeFileSync(outputPath, JSON.stringify(profile, null, 2), 'utf-8');
   ```

7. Output result:
   ```javascript
   output({
     output_file: outputPath,
     data_source: 'questionnaire',
     dimensions_scored: 8,
   }, raw);
   ```

**CLI dispatch (add to main() switch, after 'write-profile' case):**
```javascript
case 'profile-questionnaire': {
  const answersIdx = args.indexOf('--answers');
  const answers = answersIdx !== -1 ? args[answersIdx + 1] : null;
  const outputIdx = args.indexOf('--output');
  const outputPath = outputIdx !== -1 ? args[outputIdx + 1] : null;
  await cmdProfileQuestionnaire({ answers, outputPath }, raw);
  break;
}
```
  </action>
  <verify>
1. `node -c get-shit-done/bin/gsd-tools.js` passes (no parse errors)
2. Non-interactive test: `node get-shit-done/bin/gsd-tools.js profile-questionnaire --answers "1,2,3,4,1,2,3,4"` returns JSON with output_file
3. Verify output file contains valid profile JSON: `node -e "const p=JSON.parse(require('fs').readFileSync('/tmp/gsd-profile-xxx/questionnaire-profile.json','utf-8')); console.log(Object.keys(p.dimensions).length);"` should return 8
4. Verify all dimensions are LOW confidence: `node -e "const p=JSON.parse(require('fs').readFileSync('<output_file>','utf-8')); console.log(Object.values(p.dimensions).every(d=>d.confidence==='LOW'));"` should return true
5. Verify questionnaire output can be fed to write-profile: `node get-shit-done/bin/gsd-tools.js write-profile <questionnaire-output-file> --output /tmp/questionnaire-profile.md`
6. Verify the rendered profile has all 8 sections: `grep -c "^## " /tmp/questionnaire-profile.md` should be >= 9 (8 dimensions + metadata)
  </verify>
  <done>
`profile-questionnaire` subcommand accepts 8 answers (interactively or via `--answers` flag) and produces a profiler-compatible JSON file with all 8 dimensions at LOW confidence. The `generateClaudeInstruction` helper maps each dimension+rating to a specific, actionable Claude instruction. The output JSON has the exact same schema as session-analysis output and can be passed directly to `write-profile` to produce USER-PROFILE.md.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for profile-sample, write-profile, and profile-questionnaire</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
Add test suites to the existing test file, following the established patterns (describe blocks, beforeEach/afterEach with temp dirs, runGsdTools helper that runs gsd-tools.js via child process).

**Test Suite 1: `describe('profile-sample command', ...)`**

Setup: Create a mock sessions directory with multiple "project" subdirectories, each containing JSONL files with genuine user messages. Reuse the `createTestSession` pattern from extract-messages tests.

Tests:

1. **`test('samples messages from multiple projects proportionally')`**
   - Create 3 mock project directories: projA with 5 sessions, projB with 2 sessions, projC with 1 session
   - Each session has 10 genuine user messages
   - Run `profile-sample --path <tmpDir> --limit 30`
   - Assert: output JSON has `projects_sampled >= 2`
   - Assert: `messages_sampled <= 30`
   - Read the output JSONL file and verify messages come from multiple projects (check projectName field)

2. **`test('truncates messages to 500 chars for profiling')`**
   - Create a session with one 2000-char user message
   - Run `profile-sample --path <tmpDir>`
   - Read output JSONL, verify content length <= 515 (500 + truncation suffix)

3. **`test('filters out session continuation messages')`**
   - Create a session with messages including one starting with "This session is being continued"
   - Run `profile-sample --path <tmpDir>`
   - Read output JSONL, verify the continuation message is NOT in the output

4. **`test('returns error when no sessions directory exists')`**
   - Run `profile-sample --path /tmp/nonexistent-gsd-test-XXX`
   - Assert: command fails with error containing "No Claude Code sessions found"

5. **`test('respects --limit flag')`**
   - Create sessions with many messages
   - Run `profile-sample --path <tmpDir> --limit 5`
   - Assert: `messages_sampled <= 5`

**Test Suite 2: `describe('write-profile command', ...)`**

Setup: Create minimal valid profile JSON files for testing.

Tests:

1. **`test('renders profile from valid JSON')`**
   - Create a JSON file with 2 fully populated dimensions
   - Run `write-profile <json-file> --output <tmpDir>/test-profile.md`
   - Assert: command succeeds, output file exists
   - Assert: output contains the dimension section headers

2. **`test('handles missing dimensions gracefully')`**
   - Create a JSON file with only 1 dimension (communication_style), rest missing
   - Run `write-profile <json-file> --output <tmpDir>/test-profile.md`
   - Assert: command succeeds (does not crash)
   - Assert: output file exists and has content

3. **`test('creates output directory when missing')`**
   - Run `write-profile <json-file> --output <tmpDir>/new-subdir/profile.md`
   - Assert: file is created at the specified path
   - Assert: directory was created automatically

4. **`test('rejects invalid JSON input')`**
   - Create a file with invalid JSON content
   - Run `write-profile <invalid-file>`
   - Assert: command fails with error about reading profile JSON

5. **`test('rejects JSON missing required fields')`**
   - Create a JSON file without `profile_version` or `dimensions`
   - Run `write-profile <json-file> --output <tmpDir>/test.md`
   - Assert: command fails with error about missing required fields

6. **`test('no leftover placeholders in rendered output')`**
   - Create a JSON file with all 8 dimensions populated
   - Run `write-profile <json-file> --output <tmpDir>/test.md`
   - Read output file content
   - Assert: content does not contain `{{` (no unreplaced placeholders)

**Test Suite 3: `describe('profile-questionnaire command', ...)`**

Tests:

1. **`test('produces valid profile JSON from answers')`**
   - Run `profile-questionnaire --answers "1,2,3,4,1,2,3,4"`
   - Assert: output JSON has `output_file`, `data_source: "questionnaire"`, `dimensions_scored: 8`
   - Read the output file, parse JSON
   - Assert: `profile_version` is "1.0"
   - Assert: `data_source` is "questionnaire"
   - Assert: `dimensions` has exactly 8 keys

2. **`test('all dimensions have LOW confidence')`**
   - Run `profile-questionnaire --answers "1,1,1,1,1,1,1,1"`
   - Read output file, parse JSON
   - Assert: every dimension has `confidence: "LOW"`

3. **`test('maps answers to correct ratings')`**
   - Run `profile-questionnaire --answers "1,1,1,1,1,1,1,1"` (all first options)
   - Read output, verify:
     - communication_style.rating === "terse-direct"
     - decision_speed.rating === "fast-intuitive"
     - explanation_depth.rating === "code-only"
     - debugging_approach.rating === "fix-first"
     - ux_philosophy.rating === "function-first"
     - vendor_philosophy.rating === "pragmatic-fast"
     - frustration_triggers.rating === "scope-creep"
     - learning_style.rating === "self-directed"

4. **`test('rejects wrong number of answers')`**
   - Run `profile-questionnaire --answers "1,2,3"`
   - Assert: command fails with error about expecting 8 answers

5. **`test('questionnaire output compatible with write-profile')`**
   - Run `profile-questionnaire --answers "2,2,2,2,2,2,2,2"`
   - Get output_file from result
   - Run `write-profile <output_file> --output <tmpDir>/q-profile.md`
   - Assert: command succeeds
   - Assert: rendered profile contains all 8 dimension sections

After writing tests, run the full test suite to confirm all pass (new + existing).
  </action>
  <verify>
Run `node --test get-shit-done/bin/gsd-tools.test.js` (or equivalent test runner). All new tests should pass. All existing tests (including the 14 from Phase 1 and 75 pre-existing) should still pass. Count new tests: ~16 tests across 3 suites.
  </verify>
  <done>
Test suites pass: profile-sample (5 tests), write-profile (6 tests), profile-questionnaire (5 tests). All existing tests still pass. New tests verify proportional sampling, message truncation, continuation filtering, template rendering, missing dimension handling, directory creation, invalid input handling, questionnaire answer mapping, LOW confidence enforcement, and end-to-end compatibility between questionnaire output and write-profile rendering. Total test count increased by ~16 tests.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 02-03 deliverables:

1. **Syntax check:** `node -c get-shit-done/bin/gsd-tools.js` passes
2. **Questionnaire non-interactive:** `node get-shit-done/bin/gsd-tools.js profile-questionnaire --answers "1,2,3,4,1,2,3,4"` returns JSON
3. **Questionnaire schema match:** output JSON has same top-level keys as session analysis (profile_version, analyzed_at, data_source, projects_analyzed, messages_analyzed, dimensions)
4. **All dimensions LOW:** every dimension in questionnaire output has confidence: LOW
5. **End-to-end compatibility:** questionnaire output -> write-profile -> valid USER-PROFILE.md (no errors, no leftover placeholders)
6. **All tests pass:** `node --test get-shit-done/bin/gsd-tools.test.js` exits 0
7. **No regressions:** existing 89 tests still pass alongside ~16 new tests
8. **Existing commands work:** `node get-shit-done/bin/gsd-tools.js current-timestamp` still works
</verification>

<success_criteria>
- `profile-questionnaire` produces the exact same JSON schema as session analysis output
- All questionnaire-derived dimensions are LOW confidence (self-report, not observed)
- Non-interactive `--answers` flag enables testing and agent orchestration
- Interactive mode works via readline for direct CLI usage
- `generateClaudeInstruction` maps all 8 dimensions x all ratings to specific instructions
- End-to-end: questionnaire -> write-profile -> valid USER-PROFILE.md (tested)
- All 16+ new tests pass
- All existing tests still pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/02-profiling-engine/02-03-SUMMARY.md`
</output>
