---
phase: 02-profiling-engine
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/templates/user-profile.md
autonomous: true

must_haves:
  truths:
    - "Running `gsd-tools.js profile-sample` produces a JSONL file with project-proportionally sampled messages from all Claude Code projects, capped at the batch limit"
    - "Profile sampling caps sessions per project and applies recency weighting so no single project dominates the sample"
    - "Running `gsd-tools.js write-profile --input <analysis-json>` renders a USER-PROFILE.md from profiler analysis JSON using the template"
    - "write-profile runs a post-processing regex filter on evidence quotes before writing, removing any remaining sensitive content (defense in depth Layer 2)"
    - "USER-PROFILE.md has a summary instructions block at top with behavioral directives Claude acts on immediately, plus per-dimension detail below"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "profile-sample and write-profile subcommands"
      contains: "cmdProfileSample"
    - path: "get-shit-done/templates/user-profile.md"
      provides: "USER-PROFILE.md template with placeholder markers"
      contains: "{{communication_style"
  key_links:
    - from: "main() switch"
      to: "cmdProfileSample()"
      via: "case 'profile-sample' dispatch"
      pattern: "case 'profile-sample'"
    - from: "main() switch"
      to: "cmdWriteProfile()"
      via: "case 'write-profile' dispatch"
      pattern: "case 'write-profile'"
    - from: "cmdProfileSample()"
      to: "scanProjectDir()"
      via: "Phase 1 helper for session enumeration"
      pattern: "scanProjectDir"
    - from: "cmdProfileSample()"
      to: "streamExtractMessages()"
      via: "Phase 1 helper for message extraction"
      pattern: "streamExtractMessages"
    - from: "cmdWriteProfile()"
      to: "get-shit-done/templates/user-profile.md"
      via: "template file read for rendering"
      pattern: "user-profile.md"
---

<objective>
Build the data sampling pipeline and profile rendering engine: the `profile-sample` subcommand that produces project-proportionally sampled messages for the profiler agent, the `user-profile.md` template that defines the USER-PROFILE.md structure, and the `write-profile` subcommand that renders profiler analysis JSON into the final USER-PROFILE.md file with sensitive content filtering.

Purpose: `profile-sample` solves the sampling bias problem (PROF-06) -- without it, projects with 100+ sessions would dominate the profile. `write-profile` is the rendering engine that turns structured analysis JSON into a Claude-consumable instruction document (PROF-04). The template separates structure from data, enabling future customization without code changes.

Output: `gsd-tools.js` extended with `profile-sample` and `write-profile` subcommands, `get-shit-done/templates/user-profile.md` template file.
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-profiling-engine/02-RESEARCH.md
@.planning/phases/02-profiling-engine/02-CONTEXT.md
@.planning/phases/02-profiling-engine/02-01-SUMMARY.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/references/user-profiling.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement profile-sample subcommand with project-proportional sampling</name>
  <files>get-shit-done/bin/gsd-tools.js</files>
  <action>
Add `cmdProfileSample()` to gsd-tools.js under the `// Session Pipeline Commands` section (after `cmdExtractMessages`), and wire it into the main switch.

**`async function cmdProfileSample(overridePath, options, raw)`**

Parameters:
- `overridePath`: optional path override from `--path` flag
- `options`: `{ limit: number, maxPerProject: number, maxChars: number }`
  - `limit`: total message batch limit (default: 150 -- reduced from 300 for profiling per research recommendation of 100-150 representative messages)
  - `maxPerProject`: override per-project session cap (default: auto-calculated)
  - `maxChars`: character truncation per message for profiling (default: 500 -- reduced from 2000 per research recommendation)
- `raw`: boolean for `--raw` output mode

Logic:
1. Call `getSessionsDir(overridePath)`. If null, error with same message as scan-sessions.
2. Read sessions directory, filter to directories (reuse the same pattern as cmdScanSessions and cmdExtractMessages).
3. Calculate per-project session cap: `Math.max(5, Math.floor(limit / projectDirCount))` unless `maxPerProject` is explicitly set.
4. For each project directory (sorted by lastActive descending for recency priority):
   a. Call `scanProjectDir()` to get sessions sorted by modified descending
   b. Call `readSessionIndex()` and `getProjectName()` for project name
   c. Cap sessions at the per-project limit
   d. Apply recency weighting: for sessions older than 30 days, extract fewer messages per session (e.g., max 3 per old session vs max 10 per recent session). Use `Date.now() - 30 * 24 * 60 * 60 * 1000` as the recency threshold.
   e. For each session, call `streamExtractMessages()` with `isGenuineUserMessage` filter and per-session message cap
   f. For each extracted message:
      - Truncate `content` to `maxChars` characters using `truncateContent()` (already exists from Phase 1)
      - Enrich with `projectName` field
      - Skip messages that look like session context dumps: if content starts with "This session is being continued" or content is >80% lines matching common log patterns (`/^\[?(DEBUG|INFO|WARN|ERROR|LOG)\]?/`, timestamps like `/^\d{4}-\d{2}-\d{2}/` on >80% of lines), mark as `skipped_context_dump` in metadata
   g. Add to allMessages array, respecting total batch limit

5. Write JSONL output to temp file:
   ```javascript
   const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'gsd-profile-'));
   const outputPath = path.join(tmpDir, 'profile-sample.jsonl');
   for (const msg of allMessages) {
     fs.appendFileSync(outputPath, JSON.stringify(msg) + '\n');
   }
   ```

6. Output result:
   ```json
   {
     "output_file": "path/to/profile-sample.jsonl",
     "projects_sampled": 6,
     "messages_sampled": 150,
     "per_project_cap": 25,
     "message_char_limit": 500,
     "skipped_context_dumps": 3,
     "project_breakdown": [
       { "project": "name", "messages": 25, "sessions": 5 }
     ]
   }
   ```

**Main dispatch (add to switch-case in `main()`):**
```javascript
case 'profile-sample': {
  const pathIdx = args.indexOf('--path');
  const sessionsPath = pathIdx !== -1 ? args[pathIdx + 1] : null;
  const limitIdx = args.indexOf('--limit');
  const limit = limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : 150;
  const maxPerIdx = args.indexOf('--max-per-project');
  const maxPerProject = maxPerIdx !== -1 ? parseInt(args[maxPerIdx + 1], 10) : null;
  const maxCharsIdx = args.indexOf('--max-chars');
  const maxChars = maxCharsIdx !== -1 ? parseInt(args[maxCharsIdx + 1], 10) : 500;
  await cmdProfileSample(sessionsPath, { limit, maxPerProject, maxChars }, raw);
  break;
}
```

Place after the `extract-messages` case.

**Transparency note:** Same stderr message as scan-sessions: "Reading your session history (read-only, nothing is modified or sent anywhere)..."
  </action>
  <verify>
Test the command:
1. `node get-shit-done/bin/gsd-tools.js profile-sample --json` -- should output JSON with output_file path and sampling stats
2. Verify the output JSONL file exists and contains messages with projectName field
3. `node get-shit-done/bin/gsd-tools.js profile-sample --limit 10 --json` -- should cap at 10 messages total
4. `node get-shit-done/bin/gsd-tools.js profile-sample --path /nonexistent` -- should show friendly error
5. Verify no single project contributes more than the per-project cap
  </verify>
  <done>
`profile-sample` subcommand exists in gsd-tools.js. It produces a JSONL file with project-proportionally sampled messages. Per-project session caps prevent dominant project bias. Messages are truncated to 500 chars for profiling. Session context dumps are detected and skipped. Recency weighting gives recent sessions more messages. Output includes sampling metadata.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create user-profile template and implement write-profile subcommand</name>
  <files>get-shit-done/templates/user-profile.md, get-shit-done/bin/gsd-tools.js</files>
  <action>
**Part A: Create `get-shit-done/templates/user-profile.md`**

This template defines the structure of USER-PROFILE.md. It uses `{{placeholder}}` markers (matching the existing GSD convention from CLAUDE.md template). Per user decision: this is written FOR Claude's consumption, not the developer's reading pleasure.

Use `/technical-writing` skill and `sequential-thinking` MCP when crafting this template -- per user decision.

**Template structure:**

```markdown
# Developer Profile

> This profile was generated from session analysis. It contains behavioral directives
> for Claude to follow when working with this developer. HIGH confidence dimensions
> should be acted on directly. LOW confidence dimensions should be approached with
> hedging ("Based on your profile, I'll try X -- let me know if that's off").

**Generated:** {{generated_at}}
**Source:** {{data_source}}
**Projects Analyzed:** {{projects_list}}
**Messages Analyzed:** {{message_count}}

---

## Quick Reference

{{summary_instructions}}

---

## Communication Style

**Rating:** {{communication_style.rating}} | **Confidence:** {{communication_style.confidence}}

**Directive:** {{communication_style.claude_instruction}}

{{communication_style.summary}}

**Evidence:**

{{communication_style.evidence}}

---

[... repeat for all 8 dimensions ...]

---

## Profile Metadata

| Field | Value |
|-------|-------|
| Profile Version | {{profile_version}} |
| Generated | {{generated_at}} |
| Source | {{data_source}} |
| Projects | {{projects_count}} |
| Messages | {{message_count}} |
| Dimensions Scored | {{dimensions_scored}}/8 |
| High Confidence | {{high_confidence_count}} |
| Medium Confidence | {{medium_confidence_count}} |
| Low Confidence | {{low_confidence_count}} |
| Sensitive Content Excluded | {{sensitive_excluded_summary}} |
```

IMPORTANT per user decision: Evidence is displayed inline under each dimension (no collapsed `<details>` tags, no separate files) -- Claude reads everything in one pass.

The `{{summary_instructions}}` block at the top aggregates all HIGH and MEDIUM confidence claude_instructions into a quick-reference list that Claude can act on immediately without reading the full document. Format each as a bullet point directive.

Each evidence entry uses the combined format per user decision:
- **Signal:** [pattern interpretation] / **Example:** "[trimmed quote]" -- project: [name]

**Part B: Implement `cmdWriteProfile()` in gsd-tools.js**

Add after `cmdProfileSample()` in the Session Pipeline Commands section.

**`function cmdWriteProfile(cwd, options, raw)`**

Parameters:
- `cwd`: working directory
- `options`: `{ input: string, output: string }`
  - `input`: path to analysis JSON file (from profiler agent output or questionnaire output)
  - `output`: output path for USER-PROFILE.md (default: `path.join(os.homedir(), '.claude', 'get-shit-done', 'USER-PROFILE.md')`)
- `raw`: boolean

Logic:
1. Read the analysis JSON from `options.input`. Parse it. Validate it has `dimensions` with 8 dimension keys and `profile_version`.

2. **Layer 2 sensitive content filter** (defense in depth per user decision):
   Define regex patterns for sensitive content:
   ```javascript
   const SENSITIVE_PATTERNS = [
     /sk-[a-zA-Z0-9]{20,}/g,           // Stripe/OpenAI keys
     /Bearer\s+[a-zA-Z0-9._-]+/gi,     // Bearer tokens
     /password\s*[:=]\s*\S+/gi,         // Password assignments
     /secret\s*[:=]\s*\S+/gi,           // Secret assignments
     /token\s*[:=]\s*\S+/gi,            // Token assignments
     /api[_-]?key\s*[:=]\s*\S+/gi,      // API key assignments
     /\/Users\/[a-zA-Z0-9._-]+\//g,     // macOS full paths with usernames
     /\/home\/[a-zA-Z0-9._-]+\//g,      // Linux full paths with usernames
     /ghp_[a-zA-Z0-9]{36}/g,            // GitHub personal access tokens
     /gho_[a-zA-Z0-9]{36}/g,            // GitHub OAuth tokens
     /xoxb-[a-zA-Z0-9-]+/g,            // Slack bot tokens
   ];
   ```
   Scan ALL evidence quote strings in the analysis JSON. For each match:
   - Replace the matched sensitive content with `[REDACTED]`
   - Track count of redactions for reporting
   - Log a warning to stderr: `"Sensitive content redacted: {count} pattern(s) removed from evidence quotes"`

3. Read the template from `get-shit-done/templates/user-profile.md` (relative to the gsd-tools.js location, resolved via `path.join(__dirname, '..', 'templates', 'user-profile.md')`).

4. Build the `summary_instructions` block by collecting all claude_instructions from dimensions with confidence HIGH or MEDIUM, formatted as:
   ```
   - **Communication:** [instruction] (HIGH)
   - **Decisions:** [instruction] (MEDIUM)
   ```

5. Render template by replacing `{{placeholder}}` markers with values from the analysis JSON. For each dimension, render the evidence entries in the combined format:
   ```
   - **Signal:** [signal text] / **Example:** "[quote text]" -- project: [project name]
   ```

6. Ensure output directory exists: `fs.mkdirSync(path.dirname(outputPath), { recursive: true })`.

7. Write the rendered profile to `outputPath`.

8. Output result:
   ```json
   {
     "profile_path": "~/.claude/get-shit-done/USER-PROFILE.md",
     "dimensions_scored": 8,
     "high_confidence": 3,
     "medium_confidence": 4,
     "low_confidence": 1,
     "sensitive_redacted": 0,
     "source": "session_analysis"
   }
   ```

**Main dispatch:**
```javascript
case 'write-profile': {
  const inputIdx = args.indexOf('--input');
  const inputPath = inputIdx !== -1 ? args[inputIdx + 1] : null;
  if (!inputPath) error('--input <analysis-json-path> is required');
  const outputIdx = args.indexOf('--output');
  const outputPath = outputIdx !== -1 ? args[outputIdx + 1] : null;
  cmdWriteProfile(cwd, { input: inputPath, output: outputPath }, raw);
  break;
}
```

Place after the `profile-sample` case.
  </action>
  <verify>
```bash
# Verify template exists with placeholder markers
node -e "
const fs = require('fs');
const tmpl = fs.readFileSync('get-shit-done/templates/user-profile.md', 'utf-8');
console.log(tmpl.includes('{{communication_style') ? 'PASS: Template has dimension placeholders' : 'FAIL');
console.log(tmpl.includes('{{summary_instructions}}') ? 'PASS: Template has summary block' : 'FAIL');
console.log(!tmpl.includes('<details>') ? 'PASS: No collapsed details tags' : 'FAIL: Has details tags');
"

# Verify write-profile command is wired
node -e "
const fs = require('fs');
const src = fs.readFileSync('get-shit-done/bin/gsd-tools.js', 'utf-8');
console.log(src.includes('cmdWriteProfile') ? 'PASS: write-profile function exists' : 'FAIL');
console.log(src.includes(\"case 'write-profile'\") ? 'PASS: write-profile dispatch exists' : 'FAIL');
console.log(src.includes('SENSITIVE_PATTERNS') ? 'PASS: Sensitive content filter exists' : 'FAIL');
"

# Verify syntax
node -c get-shit-done/bin/gsd-tools.js
```
  </verify>
  <done>
`user-profile.md` template exists with {{placeholder}} markers, summary instructions block at top, inline evidence under each dimension (no details tags), and metadata table. `write-profile` subcommand reads analysis JSON, applies Layer 2 sensitive content regex filter, renders template, ensures output directory exists, writes USER-PROFILE.md, and reports results. Existing commands still work.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 02-02 deliverables:

1. **Syntax check:** `node -c get-shit-done/bin/gsd-tools.js` passes
2. **Existing commands still work:** `node get-shit-done/bin/gsd-tools.js current-timestamp` returns a timestamp
3. **profile-sample basic:** `node get-shit-done/bin/gsd-tools.js profile-sample --json` produces JSON with output_file
4. **profile-sample limit:** `node get-shit-done/bin/gsd-tools.js profile-sample --limit 5 --json` caps at 5 messages
5. **Template exists:** `test -f get-shit-done/templates/user-profile.md`
6. **write-profile requires input:** `node get-shit-done/bin/gsd-tools.js write-profile 2>&1 || true` shows error about --input
7. **No sensitive content in template markers:** Template uses {{placeholder}} format matching GSD convention
</verification>

<success_criteria>
- `profile-sample` produces JSONL with project-proportionally sampled messages
- Per-project session caps prevent any single project from dominating
- Messages truncated to 500 chars for profiling context efficiency
- Session context dumps detected and skipped
- `write-profile` reads analysis JSON and renders USER-PROFILE.md from template
- Layer 2 sensitive content filter catches patterns missed by the profiler agent
- Template has summary instructions block at top and inline evidence (no details tags)
- USER-PROFILE.md written to `~/.claude/get-shit-done/USER-PROFILE.md` by default
- All existing gsd-tools.js commands continue to work
</success_criteria>

<output>
After completion, create `.planning/phases/02-profiling-engine/02-02-SUMMARY.md`
</output>
