---
phase: 02-profiling-engine
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/templates/user-profile.md
autonomous: true

must_haves:
  truths:
    - "Running `gsd-tools.js profile-sample` extracts messages from ALL projects with project-proportional sampling, capped per-project, with recency weighting"
    - "Profile sample output contains 100-150 messages truncated to 500 chars each, with projectName enrichment, written to a temp JSONL file"
    - "Running `gsd-tools.js write-profile <json-file>` reads profiler JSON output and renders USER-PROFILE.md at `~/.claude/get-shit-done/USER-PROFILE.md`"
    - "USER-PROFILE.md contains all 8 dimension sections with rating, confidence, summary, Claude instructions, and collapsible evidence"
    - "When `~/.claude/get-shit-done/` directory does not exist, write-profile creates it with `fs.mkdirSync(recursive: true)`"
    - "user-profile.md template exists with {{placeholder}} markers for all profile fields"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "profile-sample and write-profile subcommands"
      contains: "cmdProfileSample"
    - path: "get-shit-done/templates/user-profile.md"
      provides: "Template for rendering USER-PROFILE.md from profiler JSON"
      contains: "{{communication_style.rating}}"
  key_links:
    - from: "main() switch"
      to: "cmdProfileSample()"
      via: "case 'profile-sample' dispatch"
      pattern: "case 'profile-sample'"
    - from: "main() switch"
      to: "cmdWriteProfile()"
      via: "case 'write-profile' dispatch"
      pattern: "case 'write-profile'"
    - from: "cmdProfileSample()"
      to: "scanProjectDir()"
      via: "Phase 1 helper reuse for session enumeration"
      pattern: "scanProjectDir"
    - from: "cmdProfileSample()"
      to: "streamExtractMessages()"
      via: "Phase 1 helper reuse for JSONL extraction"
      pattern: "streamExtractMessages"
    - from: "cmdWriteProfile()"
      to: "get-shit-done/templates/user-profile.md"
      via: "template loading and placeholder substitution"
      pattern: "user-profile.md"
---

<objective>
Build the data sampling pipeline and profile rendering pipeline as gsd-tools.js subcommands.

Purpose: `profile-sample` prepares project-proportionally sampled messages for the profiler agent (addressing PROF-06 sampling bias). `write-profile` takes the profiler agent's JSON output and renders it into USER-PROFILE.md using a template (addressing PROF-04). Together with the agent (Plan 02-01), these form the complete profiling engine: sample data -> analyze via agent -> render profile.

Output: Two new gsd-tools.js subcommands (`profile-sample`, `write-profile`) and one new template file (`templates/user-profile.md`).
</objective>

<execution_context>
@/Users/canodevelopment/.claude/get-shit-done/workflows/execute-plan.md
@/Users/canodevelopment/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-profiling-engine/02-RESEARCH.md
@.planning/phases/01-session-data-pipeline/01-01-SUMMARY.md
@.planning/phases/01-session-data-pipeline/01-02-SUMMARY.md
@get-shit-done/bin/gsd-tools.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement profile-sample subcommand with project-proportional sampling</name>
  <files>get-shit-done/bin/gsd-tools.js</files>
  <action>
Add `cmdProfileSample` function and its CLI dispatch to gsd-tools.js. Place the function after `cmdExtractMessages` in the Session Pipeline Commands section. This subcommand implements PROF-06: project-proportional sampling with recency weighting.

**`async function cmdProfileSample(overridePath, options, raw)`**

Parameters:
- `overridePath`: optional path override (from `--path` flag, for testability)
- `options`: `{ limit: number }` -- total message limit (default 150, per research recommendation)
- `raw`: boolean for `--raw` output mode

Logic:

1. Call `getSessionsDir(overridePath)`. If returns null: error message (same pattern as scan-sessions/extract-messages).

2. Read sessions directory, get all project directories (same pattern as cmdScanSessions):
   ```javascript
   const projectDirs = fs.readdirSync(sessionsDir).filter(entry => {
     try { return fs.statSync(path.join(sessionsDir, entry)).isDirectory(); }
     catch { return false; }
   });
   ```

3. Calculate per-project session cap:
   ```javascript
   const batchLimit = options.limit || 150;
   const perProjectCap = Math.max(5, Math.floor(batchLimit / projectDirs.length));
   ```

4. Transparency note on stderr: `"Sampling your session history for profiling (read-only, nothing is modified or sent anywhere)..."`

5. For each project directory:
   a. Call `scanProjectDir(projectPath)` to get sessions (already sorted by modified descending = most recent first)
   b. Call `readSessionIndex(projectPath)` for index data
   c. Call `getProjectName(dirName, indexData)` for project name
   d. Cap sessions: `sessions.slice(0, Math.ceil(perProjectCap / 3))` -- since each session has multiple messages, take approximately perProjectCap/3 sessions to get ~perProjectCap messages
   e. For each capped session:
      - Call `streamExtractMessages(session.filePath, isGenuineUserMessage, perProjectCap)` to extract messages
      - Enrich each message with `projectName` field
      - Apply profiling truncation: `truncateContent(msg.content, 500)` -- 500 chars for profiling (shorter than pipeline's 2000, per research recommendation to keep under 200KB)
      - Add to allMessages array
      - Stop if allMessages.length >= batchLimit
   f. If allMessages.length >= batchLimit: stop processing more projects

6. Content-type heuristics for deprioritization (per research open question #3):
   - Filter out messages where `content.startsWith('This session is being continued')` -- session continuations
   - Filter out messages where content is predominantly log output: check if >80% of lines match timestamp/log patterns (lines starting with `[`, ISO date patterns, repeated format strings). Simple heuristic: if more than 4 lines start with `[` or contain `[DEBUG]`, `[INFO]`, `[ERROR]`, `[WARN]`, skip the message.

7. Sort remaining messages: interleave by project (round-robin) so the profiler sees variety, not one project's block then another's. Implementation: group by projectName, then interleave:
   ```javascript
   const byProject = {};
   for (const msg of allMessages) {
     (byProject[msg.projectName] = byProject[msg.projectName] || []).push(msg);
   }
   const interleaved = [];
   let maxLen = Math.max(...Object.values(byProject).map(a => a.length));
   for (let i = 0; i < maxLen; i++) {
     for (const project of Object.keys(byProject)) {
       if (byProject[project][i]) interleaved.push(byProject[project][i]);
     }
   }
   const finalMessages = interleaved.slice(0, batchLimit);
   ```

8. Write to temp file:
   ```javascript
   const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'gsd-profile-'));
   const outputPath = path.join(tmpDir, 'profile-sample.jsonl');
   for (const msg of finalMessages) {
     fs.appendFileSync(outputPath, JSON.stringify(msg) + '\n');
   }
   ```

9. Output result:
   ```javascript
   output({
     output_file: outputPath,
     projects_sampled: Object.keys(byProject).length,
     messages_sampled: finalMessages.length,
     per_project_cap: perProjectCap,
     batch_limit: batchLimit,
   }, raw);
   ```

**CLI dispatch (add to main() switch, after 'extract-messages' case):**
```javascript
case 'profile-sample': {
  const pathIdx = args.indexOf('--path');
  const sessionsPath = pathIdx !== -1 ? args[pathIdx + 1] : null;
  const limitIdx = args.indexOf('--limit');
  const limit = limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : null;
  await cmdProfileSample(sessionsPath, { limit }, raw);
  break;
}
```
  </action>
  <verify>
1. `node -c get-shit-done/bin/gsd-tools.js` passes (no parse errors)
2. `node get-shit-done/bin/gsd-tools.js profile-sample` runs against real session data and returns JSON with `output_file`, `projects_sampled`, `messages_sampled`
3. Verify output file contains JSONL with `projectName` field: `head -3 <output_file_path>`
4. Verify messages are truncated to ~500 chars, not 2000: `node -e "const fs=require('fs'); const lines=fs.readFileSync('<output_file>','utf-8').trim().split('\\n'); const maxLen=Math.max(...lines.map(l=>JSON.parse(l).content.length)); console.log('max content length:', maxLen);"` should be <= 515 (500 + truncation suffix)
5. Verify multiple projects are sampled: check `projects_sampled > 1` in output JSON
  </verify>
  <done>
`profile-sample` subcommand extracts messages from all projects with project-proportional sampling. Messages are capped at 150 total (configurable via --limit), truncated to 500 chars for profiling, enriched with projectName, interleaved by project for variety, with session continuation and log-paste messages filtered out. Output written to temp JSONL file.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create user-profile template and implement write-profile subcommand</name>
  <files>get-shit-done/templates/user-profile.md, get-shit-done/bin/gsd-tools.js</files>
  <action>
**Part A: Create `get-shit-done/templates/user-profile.md`**

This template uses `{{placeholder}}` markers that `write-profile` replaces with data from the profiler's JSON output. Follow the template convention established in PROJECT.md Key Decisions.

Template content:

```markdown
# Developer Profile

**Generated:** {{generated_at}}
**Source:** {{data_source}}
**Projects Analyzed:** {{projects_list}}
**Messages Analyzed:** {{message_count}}

---

{{dimension_sections}}

---

## Profile Metadata

| Field | Value |
|-------|-------|
| Profile Version | {{profile_version}} |
| Generated | {{generated_at}} |
| Source | {{data_source}} |
| Projects | {{projects_count}} |
| Messages | {{message_count}} |
| Dimensions Scored | {{dimensions_scored}}/8 |
| High Confidence | {{high_confidence_count}} |
| Medium Confidence | {{medium_confidence_count}} |
| Low Confidence | {{low_confidence_count}} |

---
*Generated by GSD-Plus profiling engine*
*Edit this file freely -- re-running the profiler will overwrite it*
```

The `{{dimension_sections}}` placeholder is replaced programmatically by the write-profile command, which generates a section per dimension using this per-dimension template:

```markdown
## [Dimension Name]

**Rating:** [rating]
**Confidence:** [confidence]

[summary]

**Claude Instructions:**
[claude_instruction]

<details>
<summary>Evidence ([evidence_count] signals)</summary>

[For each evidence quote:]
> "[quote]"
> -- [project], session [session_id]
> Signal: [signal]

</details>
```

**Part B: Implement `cmdWriteProfile` in gsd-tools.js**

Add `cmdWriteProfile` function after `cmdProfileSample` in the Session Pipeline Commands section.

**`function cmdWriteProfile(cwd, jsonFilePath, options, raw)`**

Parameters:
- `cwd`: current working directory (unused but follows convention)
- `jsonFilePath`: path to the profiler's JSON output file
- `options`: `{ outputPath: string|null }` -- override output path (default: `~/.claude/get-shit-done/USER-PROFILE.md`)
- `raw`: boolean

Logic:

1. Read the JSON file:
   ```javascript
   let profileData;
   try {
     const content = fs.readFileSync(jsonFilePath, 'utf-8');
     profileData = JSON.parse(content);
   } catch (err) {
     error(`Cannot read profile JSON: ${err.message}`);
   }
   ```

2. Validate required fields:
   - `profileData.profile_version` must exist
   - `profileData.dimensions` must be an object
   - `profileData.dimensions` must have at least 1 key
   - If validation fails: `error('Invalid profile JSON: missing required fields (profile_version, dimensions)')`

3. Build dimension sections. Define a dimension display name map:
   ```javascript
   const DIMENSION_NAMES = {
     communication_style: 'Communication Style',
     decision_speed: 'Decision Speed',
     explanation_depth: 'Explanation Depth',
     debugging_approach: 'Debugging Approach',
     ux_philosophy: 'UX Philosophy',
     vendor_philosophy: 'Vendor Philosophy',
     frustration_triggers: 'Frustration Triggers',
     learning_style: 'Learning Style',
   };
   ```

4. For each dimension key in DIMENSION_NAMES order (to ensure consistent section ordering):
   a. Get dimension data from `profileData.dimensions[key]`
   b. If dimension data is missing or null: create a placeholder section with "Not analyzed" rating and LOW confidence
   c. Build section markdown:
      ```
      ## [Display Name]

      **Rating:** [rating]
      **Confidence:** [confidence]

      [summary]

      **Claude Instructions:**
      [claude_instruction]

      <details>
      <summary>Evidence ([evidence_count] signals)</summary>

      [for each quote in evidence_quotes:]
      > "[quote]"
      > -- [project], session [session_id]
      > Signal: [signal]

      </details>
      ```
   d. Append section to dimensionSections string with `---` separator between sections

5. Calculate metadata:
   ```javascript
   const dims = Object.values(profileData.dimensions);
   const highCount = dims.filter(d => d && d.confidence === 'HIGH').length;
   const mediumCount = dims.filter(d => d && d.confidence === 'MEDIUM').length;
   const lowCount = dims.filter(d => d && d.confidence === 'LOW').length;
   const dimensionsScored = dims.filter(d => d && d.rating !== 'insufficient_data').length;
   ```

6. Read the template from `get-shit-done/templates/user-profile.md`. Resolve the template path relative to the gsd-tools.js location:
   ```javascript
   const toolsDir = path.dirname(__filename);
   const templatePath = path.join(toolsDir, '..', 'templates', 'user-profile.md');
   ```
   Wait -- `__filename` is available in Node.js. The existing code uses `process.argv[1]` for script path. Use the pattern:
   ```javascript
   const gsdDir = path.resolve(path.dirname(process.argv[1]), '..');
   const templatePath = path.join(gsdDir, 'templates', 'user-profile.md');
   ```

7. Replace all `{{placeholder}}` markers in the template:
   ```javascript
   let output = template
     .replace(/\{\{generated_at\}\}/g, profileData.analyzed_at || new Date().toISOString())
     .replace(/\{\{data_source\}\}/g, profileData.data_source || 'unknown')
     .replace(/\{\{projects_list\}\}/g, (profileData.projects_analyzed || []).join(', '))
     .replace(/\{\{message_count\}\}/g, String(profileData.messages_analyzed || 0))
     .replace(/\{\{dimension_sections\}\}/g, dimensionSections)
     .replace(/\{\{profile_version\}\}/g, profileData.profile_version || '1.0')
     .replace(/\{\{projects_count\}\}/g, String((profileData.projects_analyzed || []).length))
     .replace(/\{\{dimensions_scored\}\}/g, String(dimensionsScored))
     .replace(/\{\{high_confidence_count\}\}/g, String(highCount))
     .replace(/\{\{medium_confidence_count\}\}/g, String(mediumCount))
     .replace(/\{\{low_confidence_count\}\}/g, String(lowCount));
   ```

8. Determine output path:
   ```javascript
   const profileDir = options.outputPath
     ? path.dirname(options.outputPath)
     : path.join(os.homedir(), '.claude', 'get-shit-done');
   const profilePath = options.outputPath
     || path.join(profileDir, 'USER-PROFILE.md');
   ```

9. Ensure directory exists:
   ```javascript
   fs.mkdirSync(profileDir, { recursive: true });
   ```

10. Write the file:
    ```javascript
    fs.writeFileSync(profilePath, rendered, 'utf-8');
    ```

11. Output result:
    ```javascript
    output({
      profile_path: profilePath,
      dimensions_scored: dimensionsScored,
      high_confidence: highCount,
      medium_confidence: mediumCount,
      low_confidence: lowCount,
    }, raw);
    ```

**CLI dispatch (add to main() switch, after 'profile-sample' case):**
```javascript
case 'write-profile': {
  const jsonFile = args[1];
  if (!jsonFile) {
    error('Usage: gsd-tools write-profile <profile-json-file> [--output <path>]');
  }
  const outputIdx = args.indexOf('--output');
  const outputPath = outputIdx !== -1 ? args[outputIdx + 1] : null;
  cmdWriteProfile(cwd, jsonFile, { outputPath }, raw);
  break;
}
```
  </action>
  <verify>
1. `node -c get-shit-done/bin/gsd-tools.js` passes (no parse errors)
2. Verify template exists: `test -f get-shit-done/templates/user-profile.md && echo "OK"`
3. Create a test JSON file and verify write-profile works:
   ```bash
   cat > /tmp/test-profile.json << 'EOF'
   {
     "profile_version": "1.0",
     "analyzed_at": "2026-02-13T00:00:00Z",
     "data_source": "session_analysis",
     "projects_analyzed": ["TestProject"],
     "messages_analyzed": 50,
     "dimensions": {
       "communication_style": {
         "rating": "detailed-structured",
         "confidence": "HIGH",
         "evidence_count": 15,
         "cross_project_consistent": true,
         "evidence_quotes": [{"quote": "Test quote", "session_id": "abc", "project": "TestProject", "signal": "Test signal"}],
         "summary": "Test summary",
         "claude_instruction": "Test instruction"
       }
     }
   }
   EOF
   node get-shit-done/bin/gsd-tools.js write-profile /tmp/test-profile.json --output /tmp/test-USER-PROFILE.md
   ```
4. Verify the rendered profile has correct content: `grep "Communication Style" /tmp/test-USER-PROFILE.md`
5. Verify placeholder substitution: `grep "{{" /tmp/test-USER-PROFILE.md` should return NO matches (all placeholders replaced)
6. Verify existing commands still work: `node get-shit-done/bin/gsd-tools.js current-timestamp`
  </verify>
  <done>
`user-profile.md` template exists with `{{placeholder}}` markers for all profile fields. `write-profile` subcommand reads profiler JSON output, validates required fields, builds per-dimension sections with rating/confidence/summary/evidence/Claude instructions, replaces all template placeholders, creates the output directory if needed, and writes USER-PROFILE.md. The template separates structure from data and supports both session-analysis and questionnaire-derived profiles.
  </done>
</task>

</tasks>

<verification>
Run these checks to verify Plan 02-02 deliverables:

1. **Syntax check:** `node -c get-shit-done/bin/gsd-tools.js` passes
2. **Template exists:** `test -f get-shit-done/templates/user-profile.md && echo "OK"`
3. **Template has placeholders:** `grep -c "{{" get-shit-done/templates/user-profile.md` returns > 0
4. **profile-sample runs:** `node get-shit-done/bin/gsd-tools.js profile-sample` returns JSON with output_file
5. **profile-sample multiple projects:** output JSON shows `projects_sampled > 1`
6. **profile-sample message cap:** output JSON shows `messages_sampled <= 150`
7. **write-profile runs:** `node get-shit-done/bin/gsd-tools.js write-profile /tmp/test-profile.json --output /tmp/test-profile.md` produces a valid markdown file
8. **write-profile renders all sections:** rendered output contains "Communication Style" or dimension name
9. **write-profile no leftover placeholders:** `grep "{{" /tmp/test-profile.md` returns empty
10. **Existing commands work:** `node get-shit-done/bin/gsd-tools.js current-timestamp` still works
</verification>

<success_criteria>
- `profile-sample` extracts messages from ALL projects with proportional sampling, not just the largest
- Sample output stays within 150 messages (configurable), 500 chars each
- Messages are enriched with projectName and interleaved by project
- Session continuations and log dumps are filtered out
- `write-profile` renders any valid profiler JSON into USER-PROFILE.md
- Template uses `{{placeholder}}` markers per the project decision
- Missing dimensions get placeholder sections (not errors)
- Output directory created automatically if missing
- Both subcommands follow existing gsd-tools.js patterns (error handling, stderr transparency, JSON output)
</success_criteria>

<output>
After completion, create `.planning/phases/02-profiling-engine/02-02-SUMMARY.md`
</output>
